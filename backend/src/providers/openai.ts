import * as types from '../types'
import * as provider from './provider'
import * as utils from '../utils'
import { redirectModel } from '../config/config'

export class impl implements provider.Provider {
  async convertToProviderRequest(
    request: Request,
    baseUrl: string,
    apiKey: string,
    upstream?: import('../config/config').UpstreamConfig
  ): Promise<Request> {
    const claudeRequest = (await request.json()) as types.ClaudeRequest
    const openaiRequest = this.convertToOpenAIRequestBody(claudeRequest, upstream)

    const finalUrl = utils.buildUrl(baseUrl, 'chat/completions')

    const headers = new Headers(request.headers)
    headers.set('Authorization', `Bearer ${apiKey}`)
    headers.set('Content-Type', 'application/json')
    const upstreamHost = new URL(baseUrl).hostname
    headers.set('Host', upstreamHost)

    return new Request(finalUrl, {
      method: 'POST',
      headers,
      body: JSON.stringify(openaiRequest)
    })
  }

  async convertToClaudeResponse(openaiResponse: Response): Promise<Response> {
    if (!openaiResponse.ok) {
      return openaiResponse
    }

    const contentType = openaiResponse.headers.get('content-type') || ''
    const isStream = contentType.includes('text/event-stream')

    if (isStream) {
      return this.convertStreamResponse(openaiResponse)
    } else {
      return this.convertNormalResponse(openaiResponse)
    }
  }

  // å…¼å®¹å„ç§æ¥æºçš„ role å€¼ï¼ˆå¦‚ 'tools'ã€'system' ç­‰ï¼‰
  private normalizeClaudeRole = utils.normalizeClaudeRole

  // æ”¯æŒ Claude é¡¶å±‚ system ä¸º string æˆ– content[]ï¼ˆå« {type:'text'} å—ï¼‰
  private extractSystemText(systemField: any): string | undefined {
    if (!systemField) return undefined
    if (typeof systemField === 'string') return systemField
    // å¯èƒ½æ˜¯å•ä¸ªå¯¹è±¡æˆ–æ•°ç»„
    const arr = Array.isArray(systemField) ? systemField : [systemField]
    const parts: string[] = []
    for (const item of arr) {
      if (item && typeof item === 'object' && item.type === 'text' && typeof item.text === 'string') {
        parts.push(item.text)
      }
    }
    if (parts.length === 0) return undefined
    return parts.join('\n')
  }

  private convertToOpenAIRequestBody(
    claudeRequest: types.ClaudeRequest,
    upstream?: import('../config/config').UpstreamConfig
  ): types.OpenAIRequest {
    const convertedMessages = this.convertMessages(claudeRequest.messages)
    const systemText = this.extractSystemText((claudeRequest as any).system)
    const messages: types.OpenAIMessage[] = systemText
      ? [{ role: 'system', content: systemText }, ...convertedMessages]
      : convertedMessages

    // åº”ç”¨æ¨¡å‹é‡å®šå‘
    const finalModel = upstream ? redirectModel(claudeRequest.model, upstream) : claudeRequest.model

    const openaiRequest: types.OpenAIRequest = {
      model: finalModel,
      messages,
      stream: claudeRequest.stream
    }

    if (claudeRequest.tools && claudeRequest.tools.length > 0) {
      openaiRequest.tools = claudeRequest.tools.map(tool => ({
        type: 'function',
        function: {
          name: tool.name,
          description: tool.description,
          parameters: utils.cleanJsonSchema(tool.input_schema)
        }
      }))
      openaiRequest.tool_choice = 'auto'
    }

    if (claudeRequest.temperature !== undefined) {
      openaiRequest.temperature = claudeRequest.temperature
    }

    if (claudeRequest.max_tokens !== undefined) {
      // ä½¿ç”¨æ–°ç‰ˆå­—æ®µä»¥å…¼å®¹ o4 ç³»åˆ—åŠæ–°æ¥å£è¡Œä¸º
      openaiRequest.max_completion_tokens = claudeRequest.max_tokens
    } else {
      openaiRequest.max_completion_tokens = 65535
    }

    return openaiRequest
  }

  private convertMessages(claudeMessages: types.ClaudeMessage[]): types.OpenAIMessage[] {
    const openaiMessages: types.OpenAIMessage[] = []
    const toolCallMap = new Map<string, string>()

    for (const message of claudeMessages) {
      const normalizedRole = this.normalizeClaudeRole((message as any).role)
      if (typeof message.content === 'string') {
        // çº¯æ–‡æœ¬æ¶ˆæ¯ï¼šæ”¯æŒ system/user/assistantï¼›tool è§’è‰²çš„çº¯æ–‡æœ¬å¿½ç•¥
        if (normalizedRole !== 'tool') {
          openaiMessages.push({
            role: normalizedRole,
            content: message.content
          })
        }
        continue
      }

      const textContents: string[] = []
      const toolCalls: types.OpenAIToolCall[] = []
      const toolResults: Array<{ tool_call_id: string; content: string }> = []

      for (const content of message.content) {
        switch (content.type) {
          case 'text':
            textContents.push(content.text)
            break
          case 'tool_use':
            toolCallMap.set(content.id, content.id)
            toolCalls.push({
              id: content.id,
              type: 'function',
              function: {
                name: content.name,
                arguments: JSON.stringify(content.input)
              }
            })
            break
          case 'tool_result':
            toolResults.push({
              tool_call_id: content.tool_use_id,
              content: typeof content.content === 'string' ? content.content : JSON.stringify(content.content)
            })
            break
        }
      }

      // ä¼˜å…ˆæ¨é€ tool_resultï¼Œç¡®ä¿ç´§è·Ÿåœ¨ä¸Šä¸€æ¬¡ assistant çš„ tool_calls ä¹‹å
      for (const toolResult of toolResults) {
        openaiMessages.push({
          role: 'tool',
          tool_call_id: toolResult.tool_call_id,
          content: toolResult.content
        })
      }

      if ((textContents.length > 0 || toolCalls.length > 0) && normalizedRole !== 'tool') {
        const openaiMessage: types.OpenAIMessage = {
          role: normalizedRole === 'assistant' ? 'assistant' : normalizedRole === 'system' ? 'system' : 'user',
          content: textContents.length > 0 ? textContents.join('\n') : null
        }

        if (toolCalls.length > 0) {
          openaiMessage.tool_calls = toolCalls
        }

        openaiMessages.push(openaiMessage)
      }
    }

    return openaiMessages
  }

  private async convertNormalResponse(openaiResponse: Response): Promise<Response> {
    const openaiData = (await openaiResponse.json()) as types.OpenAIResponse

    const claudeResponse: types.ClaudeResponse = {
      id: utils.generateId(),
      type: 'message',
      role: 'assistant',
      content: []
    }

    if (openaiData.choices && openaiData.choices.length > 0) {
      const choice = openaiData.choices[0]
      const message = choice.message

      if (message.content) {
        claudeResponse.content.push({
          type: 'text',
          text: message.content
        })
      }

      if (message.tool_calls) {
        for (const toolCall of message.tool_calls) {
          claudeResponse.content.push({
            type: 'tool_use',
            id: toolCall.id,
            name: toolCall.function.name,
            input: (() => {
              try {
                return JSON.parse(toolCall.function.arguments)
              } catch (e) {
                console.error(`Error parsing toolCall arguments for ${toolCall.function.name}:`, toolCall.function.arguments, e)
                return toolCall.function.arguments // Fallback to raw string if parsing fails
              }
            })()
          })
        }
        claudeResponse.stop_reason = 'tool_use'
      } else if (choice.finish_reason === 'length') {
        claudeResponse.stop_reason = 'max_tokens'
      } else {
        claudeResponse.stop_reason = 'end_turn'
      }
    }

    if (openaiData.usage) {
      claudeResponse.usage = {
        input_tokens: openaiData.usage.prompt_tokens,
        output_tokens: openaiData.usage.completion_tokens
      }
    }

    return new Response(JSON.stringify(claudeResponse), {
      status: openaiResponse.status,
      headers: {
        'Content-Type': 'application/json'
      }
    })
  }

  private async convertStreamResponse(openaiResponse: Response): Promise<Response> {
    // ç”¨äºç´¯ç§¯å·¥å…·è°ƒç”¨æ•°æ®
    const toolCallAccumulator = new Map<number, { id?: string; name?: string; arguments?: string }>()
    // ä»…åœ¨ç¡®è®¤ OpenAI æœ¬è½®ä»¥ tool_calls ç»“æŸæ—¶ï¼Œå‘ä¸‹æ¸¸å‘é€ä¸€æ¬¡ stop_reason=tool_use
    let toolUseStopEmitted = false

    return utils.processProviderStream(openaiResponse, (jsonStr, textBlockIndex, toolUseBlockIndex) => {
      let openaiData: any
      try {
        openaiData = JSON.parse(jsonStr)
      } catch (e) {
        console.warn(`[${new Date().toISOString()}] ğŸŸ¡ OpenAI stream JSON parse error, skipping a chunk.`)
        return null
      }

      // å…³é”®ä¿®å¤ï¼šæ£€æŸ¥ä¸Šæ¸¸æµä¸­æ˜¯å¦ç›´æ¥è¿”å›äº†é”™è¯¯å¯¹è±¡
      if (openaiData.error) {
        console.error(`[${new Date().toISOString()}] ğŸš¨ Upstream error in stream:`, JSON.stringify(openaiData.error))
        throw new Error(`Upstream stream error: ${openaiData.error.message || JSON.stringify(openaiData.error)}`)
      }

      if (!openaiData || !openaiData.choices || !openaiData.choices.length) {
        return null
      }

      const choice = openaiData.choices[0]
      const delta = choice.delta
      const events: string[] = []
      let currentTextIndex = textBlockIndex
      let currentToolIndex = toolUseBlockIndex

      if (delta.content) {
        events.push(...utils.processTextPart(delta.content, currentTextIndex))
        currentTextIndex++
      }

      if (delta.tool_calls) {
        for (const toolCall of delta.tool_calls) {
          const toolIndex = toolCall.index ?? 0

          // è·å–æˆ–åˆ›å»ºå·¥å…·è°ƒç”¨ç´¯ç§¯å™¨
          if (!toolCallAccumulator.has(toolIndex)) {
            toolCallAccumulator.set(toolIndex, {})
          }
          const accumulated = toolCallAccumulator.get(toolIndex)!

          // ç´¯ç§¯æ•°æ®
          if (toolCall.id) {
            accumulated.id = toolCall.id
          }
          if (toolCall.function?.name) {
            accumulated.name = toolCall.function.name
          }
          if (toolCall.function?.arguments) {
            accumulated.arguments = (accumulated.arguments || '') + toolCall.function.arguments
          }

          // æ£€æŸ¥æ˜¯å¦æ”¶é›†å®Œæ•´ï¼ˆåŒ…å« id/name/argsï¼‰ï¼Œå¹¶ä¸”argumentsæ˜¯æœ‰æ•ˆJSON
          if (accumulated.id && accumulated.name && accumulated.arguments) {
            try {
              const args = JSON.parse(accumulated.arguments)
              events.push(
                ...utils.processToolUsePart(
                  {
                    id: accumulated.id,
                    name: accumulated.name,
                    args: args
                  },
                  currentToolIndex
                )
              )
              currentToolIndex++
              // æ¸…é™¤å·²å¤„ç†çš„å·¥å…·è°ƒç”¨
              toolCallAccumulator.delete(toolIndex)
            } catch (e) {
              // JSONè¿˜ä¸å®Œæ•´ï¼Œç»§ç»­ç´¯ç§¯
            }
          }
        }
      }

      // ä»…å½“ OpenAI æ˜ç¡®ä»¥ tool_calls ç»“æŸæ—¶ï¼Œå†å‘é€ä¸€æ¬¡ stop_reason=tool_useï¼Œé¿å…å¹¶è¡Œå¤šå·¥å…·æ—¶æå‰ç»“æŸ
      if (!toolUseStopEmitted && (choice.finish_reason === 'tool_calls' || choice.finish_reason === 'function_call')) {
        events.push(
          `event: message_delta\n` +
            `data: ${JSON.stringify({
              type: 'message_delta',
              delta: { stop_reason: 'tool_use' }
            })}\n\n`
        )
        toolUseStopEmitted = true
      }

      return {
        events,
        textBlockIndex: currentTextIndex,
        toolUseBlockIndex: currentToolIndex
      }
    })
  }
}
