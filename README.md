# Claude API ä»£ç†æœåŠ¡å™¨

ä¸€ä¸ªé«˜æ€§èƒ½çš„ Claude API ä»£ç†æœåŠ¡å™¨ï¼Œæ”¯æŒå¤šç§ä¸Šæ¸¸ AI æœåŠ¡æä¾›å•†ï¼ˆOpenAIã€Geminiã€è‡ªå®šä¹‰ APIï¼‰ï¼Œæä¾›è´Ÿè½½å‡è¡¡ã€å¤š API å¯†é’¥ç®¡ç†å’Œç»Ÿä¸€å…¥å£è®¿é—®ã€‚

## ğŸš€ åŠŸèƒ½ç‰¹æ€§

- **ç»Ÿä¸€å…¥å£**: æ‰€æœ‰è¯·æ±‚é€šè¿‡å•ä¸€ç«¯ç‚¹ `http://localhost:3000/v1/messages` è®¿é—®
- **å¤šä¸Šæ¸¸æ”¯æŒ**: æ”¯æŒ OpenAIã€Geminiã€è‡ªå®šä¹‰ API æœåŠ¡å•†
- **è´Ÿè½½å‡è¡¡**: æ”¯æŒè½®è¯¢ã€éšæœºã€æ•…éšœè½¬ç§»ç­–ç•¥
- **å¤š API å¯†é’¥**: æ¯ä¸ªä¸Šæ¸¸å¯é…ç½®å¤šä¸ª API å¯†é’¥ï¼Œè‡ªåŠ¨è½®æ¢ä½¿ç”¨
- **é…ç½®ç®¡ç†**: å‘½ä»¤è¡Œå·¥å…·è½»æ¾ç®¡ç†ä¸Šæ¸¸é…ç½®
- **ç¯å¢ƒå˜é‡**: é€šè¿‡ `.env` æ–‡ä»¶çµæ´»é…ç½®æœåŠ¡å™¨å‚æ•°
- **å¥åº·æ£€æŸ¥**: å†…ç½®å¥åº·æ£€æŸ¥ç«¯ç‚¹
- **æ—¥å¿—ç³»ç»Ÿ**: å®Œæ•´çš„è¯·æ±‚/å“åº”æ—¥å¿—è®°å½•
- **ğŸ”„ å…¼å®¹ Claude Code**: é…åˆ [One-Balance](https://github.com/glidea/one-balance) ä½æˆæœ¬ä½¿ç”¨ Claude Code
- **ğŸ“¡ æ”¯æŒæµå¼å’Œéæµå¼å“åº”**
- **ğŸ› ï¸ æ”¯æŒå·¥å…·è°ƒç”¨**

## ğŸ“¦ å®‰è£…

### å‰ç½®è¦æ±‚

- Node.js 18+ æˆ– Bun
- pnpm åŒ…ç®¡ç†å™¨

### å®‰è£…æ­¥éª¤

1. å…‹éš†é¡¹ç›®

```bash
git clone https://github.com/glidea/claude-worker-proxy
cd claude-worker-proxy
```

2. å®‰è£…ä¾èµ–

```bash
pnpm install
```

3. é…ç½®ç¯å¢ƒå˜é‡

```bash
cp .env.example .env
# ç¼–è¾‘ .env æ–‡ä»¶ï¼Œè®¾ç½®ä½ çš„é…ç½®
```

4. å¯åŠ¨æœåŠ¡å™¨

```bash
# ç”Ÿäº§ç¯å¢ƒ
pnpm start

# å¼€å‘ç¯å¢ƒï¼ˆçƒ­é‡è½½ï¼‰
pnpm dev:local
```

## âš™ï¸ é…ç½®

### ä»£ç†è®¿é—®å¯†é’¥é…ç½®

ä»£ç†æœåŠ¡å™¨éœ€è¦ä¸€ä¸ªè®¿é—®å¯†é’¥æ¥éªŒè¯å®¢æˆ·ç«¯è¯·æ±‚ã€‚è¿™ä¸ªå¯†é’¥é€šè¿‡ç¯å¢ƒå˜é‡ `PROXY_ACCESS_KEY` é…ç½®ï¼š

```env
PROXY_ACCESS_KEY=your-proxy-access-key
```

**å¯†é’¥è¯´æ˜**ï¼š

- **ä»£ç†è®¿é—®å¯†é’¥**: åœ¨ `.env` æ–‡ä»¶ä¸­é…ç½®ï¼Œç”¨äºéªŒè¯å®¢æˆ·ç«¯å¯¹ä»£ç†æœåŠ¡å™¨çš„è®¿é—®æƒé™
- **ä¸Šæ¸¸ API å¯†é’¥**: é€šè¿‡ `bun run config key` å‘½ä»¤é…ç½®ï¼Œç”¨äºä»£ç†æœåŠ¡å™¨è®¿é—®ä¸Šæ¸¸ AI æœåŠ¡å•†

### ç¯å¢ƒå˜é‡é…ç½®

åˆ›å»º `.env` æ–‡ä»¶ï¼ˆå‚è€ƒ `.env.example`ï¼‰ï¼š

```env
# æœåŠ¡å™¨é…ç½®
PORT=3000
NODE_ENV=development

# ä»£ç†è®¿é—®å¯†é’¥ - ç”¨äºéªŒè¯å®¢æˆ·ç«¯å¯¹ä»£ç†æœåŠ¡å™¨çš„è®¿é—®æƒé™
PROXY_ACCESS_KEY=your-proxy-access-key

# è´Ÿè½½å‡è¡¡ç­–ç•¥ (round-robin, random, failover)
LOAD_BALANCE_STRATEGY=failover

# æ—¥å¿—çº§åˆ« (error, warn, info, debug)
LOG_LEVEL=debug

# æ˜¯å¦å¯ç”¨è¯·æ±‚/å“åº”æ—¥å¿—
ENABLE_REQUEST_LOGS=true
ENABLE_RESPONSE_LOGS=true

# è¯·æ±‚è¶…æ—¶æ—¶é—´ï¼ˆæ¯«ç§’ï¼‰
REQUEST_TIMEOUT=30000

# æœ€å¤§å¹¶å‘è¯·æ±‚æ•°
MAX_CONCURRENT_REQUESTS=100

# CORSé…ç½®
ENABLE_CORS=true
CORS_ORIGIN=*

# å®‰å…¨é…ç½®
ENABLE_RATE_LIMIT=false
RATE_LIMIT_WINDOW=60000
RATE_LIMIT_MAX_REQUESTS=100

# å¥åº·æ£€æŸ¥é…ç½®
HEALTH_CHECK_ENABLED=true
HEALTH_CHECK_PATH=/health
```

### ä¸Šæ¸¸é…ç½®ç®¡ç†

ä½¿ç”¨å‘½ä»¤è¡Œå·¥å…·ç®¡ç†ä¸Šæ¸¸é…ç½®ï¼š

```bash
# æ·»åŠ ä¸Šæ¸¸
bun run config add <name> <baseUrl> <serviceType>

# ç¤ºä¾‹
bun run config add openai-api https://api.openai.com openai
bun run config add gemini-api https://generativelanguage.googleapis.com gemini
bun run config add custom-api https://your-api.com custom

# æ·»åŠ  API å¯†é’¥
bun run config key <upstream-name> add <apiKey1> <apiKey2> ...

# åˆ—å‡º API å¯†é’¥ï¼ˆè¾“å‡ºå·²è„±æ•ï¼‰
bun run config key <index> list

# ç¤ºä¾‹
bun run config key openai-api add sk-1234567890abcdef sk-0987654321fedcba

# æŸ¥çœ‹å½“å‰é…ç½®
bun run config show

# åˆ é™¤ä¸Šæ¸¸
bun run config remove <upstream-name>

# è®¾ç½®è´Ÿè½½å‡è¡¡ç­–ç•¥
bun run config balance <strategy>

# æ¸…é™¤æ‰€æœ‰é…ç½®
bun run config clear
```

### ğŸ”§ è¯¦ç»†é…ç½®ç¤ºä¾‹

#### 1. OpenAI é…ç½®

```bash
# æ·»åŠ  OpenAI ä¸Šæ¸¸
bun run config add openai-main https://api.openai.com openai

# æ·»åŠ å¤šä¸ª API å¯†é’¥ï¼ˆæ”¯æŒè´Ÿè½½å‡è¡¡ï¼‰
bun run config key openai-main add \
  sk-proj-abc123def456... \
  sk-proj-xyz789uvw456...

# è®¾ç½®ä¸ºå½“å‰ä½¿ç”¨çš„ä¸Šæ¸¸
bun run config use openai-main
```

#### 2. Gemini é…ç½®

```bash
# æ·»åŠ  Gemini ä¸Šæ¸¸
bun run config add gemini-main https://generativelanguage.googleapis.com/v1beta gemini

# æ·»åŠ  Gemini API å¯†é’¥
bun run config key gemini-main add AIzaSyC1234567890abcdef...

# åˆ‡æ¢åˆ° Gemini
bun run config use gemini-main
```

#### 3. ç¬¬ä¸‰æ–¹ API æœåŠ¡é…ç½®

```bash
# æ·»åŠ ç¬¬ä¸‰æ–¹ Claude å…¼å®¹ API
bun run config add anthropic-proxy https://api.your-provider.com openai

# æ·»åŠ  API å¯†é’¥
bun run config key anthropic-proxy add your-api-key-here

# åˆ‡æ¢åˆ°ç¬¬ä¸‰æ–¹æœåŠ¡
bun run config use anthropic-proxy
```

#### 4. å¤šæ¸ é“é…ç½®ä¸åˆ‡æ¢

```bash
# é…ç½®å¤šä¸ªä¸Šæ¸¸æœåŠ¡
bun run config add openai-primary https://api.openai.com openai
bun run config add openai-backup https://api.openai.com openai
bun run config add gemini-backup https://generativelanguage.googleapis.com/v1beta gemini

# ä¸ºæ¯ä¸ªä¸Šæ¸¸æ·»åŠ å¯†é’¥
bun run config key openai-primary add sk-primary-key...
bun run config key openai-backup add sk-backup-key...
bun run config key gemini-backup add AIza-backup-key...

# æŸ¥çœ‹æ‰€æœ‰é…ç½®
bun run config show

# æ ¹æ®éœ€è¦åˆ‡æ¢ä¸Šæ¸¸
bun run config use openai-primary    # ä½¿ç”¨ä¸»è¦ OpenAI
bun run config use gemini-backup     # åˆ‡æ¢åˆ°å¤‡ç”¨ Gemini
```

### é…ç½®æ–‡ä»¶æ ¼å¼

é…ç½®å­˜å‚¨åœ¨ `config.json` ä¸­ï¼š

```json
{
    "upstream": [
        {
            "baseUrl": "https://api.openai.com",
            "apiKeys": ["sk-1234567890abcdef", "sk-0987654321fedcba"],
            "serviceType": "openai",
            "name": "openai-api"
        },
        {
            "baseUrl": "https://generativelanguage.googleapis.com",
            "apiKeys": ["your-gemini-api-key"],
            "serviceType": "gemini",
            "name": "gemini-api"
        }
    ],
    "currentUpstream": 0,
    "loadBalance": "failover"
}
```

## ğŸ”§ API ä½¿ç”¨

### ç»Ÿä¸€å…¥å£ç«¯ç‚¹

```
POST http://localhost:3000/v1/messages
```

### è¯·æ±‚å¤´

éœ€è¦åœ¨è¯·æ±‚å¤´ä¸­åŒ…å«ä»£ç†æœåŠ¡å™¨çš„è®¿é—®å¯†é’¥ï¼š

```bash
x-api-key: your-proxy-access-key
```

### ğŸ—ï¸ å·¥ä½œåŸç†

```mermaid
sequenceDiagram
    participant Client as å®¢æˆ·ç«¯
    participant Proxy as ä»£ç†æœåŠ¡å™¨
    participant Upstream as ä¸Šæ¸¸API

    Client->>Proxy: POST /v1/messages
    Note over Client,Proxy: åŒ…å«ä»£ç†è®¿é—®å¯†é’¥

    Proxy->>Proxy: éªŒè¯è®¿é—®å¯†é’¥
    Proxy->>Proxy: è·å–APIå¯†é’¥ (è½®è¯¢/éšæœº)
    
    Proxy->>Proxy: åè®®è½¬æ¢ (Claudeâ†’ä¸Šæ¸¸æ ¼å¼)
    Proxy->>Upstream: è½¬å‘è¯·æ±‚
    Upstream-->>Proxy: ä¸Šæ¸¸å“åº”
    
    Proxy->>Proxy: åè®®è½¬æ¢ (ä¸Šæ¸¸æ ¼å¼â†’Claude)
    Proxy-->>Client: è¿”å›Claudeæ ¼å¼å“åº”
```

### ğŸ“‹ æ”¯æŒçš„æ¨¡å‹

| æ¨¡å‹ç±»å‹ | ç¤ºä¾‹æ¨¡å‹ID | æ”¯æŒçš„æœåŠ¡å•† |
|---------|-----------|-------------|
| Claude 3.5 Sonnet | `claude-3-5-sonnet-20241022` | OpenAI, è‡ªå®šä¹‰API |
| Claude 3.5 Haiku | `claude-3-5-haiku-20241022` | OpenAI, è‡ªå®šä¹‰API |
| Claude 3 Opus | `claude-3-opus-20240229` | OpenAI, è‡ªå®šä¹‰API |
| Gemini | `gemini-1.5-pro` | Gemini |

### è¯·æ±‚æ ¼å¼

#### åŸºç¡€æ–‡æœ¬å¯¹è¯

```json
{
    "model": "claude-3-5-sonnet-20241022",
    "max_tokens": 1000,
    "messages": [
        {
            "role": "user",
            "content": "Hello, how are you?"
        }
    ]
}
```

#### æµå¼å“åº”

```json
{
    "model": "claude-3-5-sonnet-20241022",
    "max_tokens": 1000,
    "stream": true,
    "messages": [
        {
            "role": "user",
            "content": "Tell me a story"
        }
    ]
}
```

#### å·¥å…·è°ƒç”¨

```json
{
    "model": "claude-3-5-sonnet-20241022",
    "max_tokens": 1000,
    "tools": [
        {
            "type": "function",
            "function": {
                "name": "get_weather",
                "description": "Get weather information",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "location": {
                            "type": "string",
                            "description": "The city name"
                        }
                    }
                }
            }
        }
    ],
    "messages": [
        {
            "role": "user",
            "content": "What's the weather like in Shanghai?"
        }
    ]
}
```

### å“åº”æ ¼å¼

#### æ ‡å‡†å“åº”

```json
{
    "id": "msg_123456789",
    "type": "message",
    "role": "assistant",
    "content": [
        {
            "type": "text",
            "text": "I'm doing well, thank you for asking!"
        }
    ],
    "model": "claude-3-5-sonnet-20241022",
    "stop_reason": "end_turn",
    "stop_sequence": null,
    "usage": {
        "input_tokens": 15,
        "output_tokens": 12
    }
}
```

#### æµå¼å“åº”

```json
data: {"type":"message_start","message":{"id":"msg_123","type":"message","role":"assistant","content":[],"model":"claude-3-5-sonnet-20241022","stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":15,"output_tokens":0}}}

data: {"type":"content_block_start","index":0,"content_block":{"type":"text","text":""}}

data: {"type":"content_block_delta","index":0,"delta":{"type":"text_delta","text":"Hello"}}

data: {"type":"content_block_delta","index":0,"delta":{"type":"text_delta","text":"!"}}

data: {"type":"content_block_stop","index":0}

data: {"type":"message_delta","delta":{"stop_reason":"end_turn","usage":{"output_tokens":1}}}

data: {"type":"message_stop"}
```

### å®é™…ä½¿ç”¨ç¤ºä¾‹

#### cURL ç¤ºä¾‹

```bash
# åŸºç¡€å¯¹è¯
curl -X POST http://localhost:3000/v1/messages \
  -H "x-api-key: your-proxy-access-key" \
  -H "Content-Type: application/json" \
  -d '{
    "model": "claude-3-5-sonnet-20241022",
    "max_tokens": 100,
    "messages": [
      {
        "role": "user",
        "content": "Hello, how are you?"
      }
    ]
  }'

# æµå¼å“åº”
curl -X POST http://localhost:3000/v1/messages \
  -H "x-api-key: your-proxy-access-key" \
  -H "Content-Type: application/json" \
  -d '{
    "model": "claude-3-5-sonnet-20241022",
    "max_tokens": 100,
    "stream": true,
    "messages": [
      {
        "role": "user",
        "content": "Tell me a short story"
      }
    ]
  }'
```

#### Python ç¤ºä¾‹

```python
import requests
import json

# é…ç½®
base_url = "http://localhost:3000"
api_key = "your-proxy-access-key"

# å‘é€è¯·æ±‚
response = requests.post(
    f"{base_url}/v1/messages",
    headers={
        "x-api-key": api_key,
        "Content-Type": "application/json"
    },
    json={
        "model": "claude-3-5-sonnet-20241022",
        "max_tokens": 1000,
        "messages": [
            {
                "role": "user",
                "content": "Explain quantum computing in simple terms"
            }
        ]
    }
)

print(response.json())
```

#### JavaScript ç¤ºä¾‹

```javascript
// ä½¿ç”¨ fetch API
async function sendMessage(content) {
    const response = await fetch('http://localhost:3000/v1/messages', {
        method: 'POST',
        headers: {
            'x-api-key': 'your-proxy-access-key',
            'Content-Type': 'application/json'
        },
        body: JSON.stringify({
            model: 'claude-3-5-sonnet-20241022',
            max_tokens: 1000,
            messages: [
                {
                    role: 'user',
                    content: content
                }
            ]
        })
    });
    
    const data = await response.json();
    return data;
}

// ä½¿ç”¨ç¤ºä¾‹
sendMessage("What is the meaning of life?")
    .then(response => console.log(response))
    .catch(error => console.error(error));
```

## ğŸ¥ å¥åº·æ£€æŸ¥

å¥åº·æ£€æŸ¥ç«¯ç‚¹ï¼š

```
GET http://localhost:3000/health
```

å“åº”ç¤ºä¾‹ï¼š

```json
{
    "status": "healthy",
    "timestamp": "2024-01-01T00:00:00.000Z",
    "uptime": 120.5,
    "config": {
        "upstreamCount": 2,
        "currentUpstream": "openai-api",
        "loadBalance": "failover"
    }
}
```

## ğŸ“Š ç›‘æ§å’Œæ—¥å¿—

### æ—¥å¿—çº§åˆ«

- `error`: ä»…é”™è¯¯æ—¥å¿—
- `warn`: è­¦å‘Šå’Œé”™è¯¯æ—¥å¿—
- `info`: ä¸€èˆ¬ä¿¡æ¯ã€è­¦å‘Šå’Œé”™è¯¯æ—¥å¿—
- `debug`: æ‰€æœ‰æ—¥å¿—ï¼ˆåŒ…æ‹¬è°ƒè¯•ä¿¡æ¯ï¼‰

### æ—¥å¿—è¾“å‡º

æœåŠ¡å™¨ä¼šè¾“å‡ºè¯¦ç»†çš„è¿è¡Œæ—¥å¿—ï¼š

```
ğŸš€ Claude APIä»£ç†æœåŠ¡å™¨å·²å¯åŠ¨
ğŸ“ æœ¬åœ°åœ°å€: http://localhost:3000
ğŸ“‹ ç»Ÿä¸€å…¥å£: POST /v1/messages
ğŸ’š å¥åº·æ£€æŸ¥: GET /health
âš™ï¸  å½“å‰é…ç½®: openai-api - https://api.openai.com
ğŸ”§ ä½¿ç”¨ 'bun run config --help' æŸ¥çœ‹é…ç½®é€‰é¡¹
ğŸ“Š ç¯å¢ƒ: development
ğŸ” å¼€å‘æ¨¡å¼ - è¯¦ç»†æ—¥å¿—å·²å¯ç”¨
```

## ğŸ”„ è´Ÿè½½å‡è¡¡ç­–ç•¥

è´Ÿè½½å‡è¡¡ç­–ç•¥åº”ç”¨äº**å½“å‰é€‰å®šä¸Šæ¸¸å†…çš„å¤šä¸ª API å¯†é’¥**ï¼Œè€Œä¸æ˜¯åœ¨å¤šä¸ªä¸Šæ¸¸ä¹‹é—´åˆ‡æ¢ã€‚ä½ å¯ä»¥é€šè¿‡ `bun run config use <index>` æ¥é€‰æ‹©è¦ä½¿ç”¨çš„ä¸Šæ¸¸ã€‚

### 1. è½®è¯¢ (round-robin)

æŒ‰é¡ºåºè½®æµä½¿ç”¨å½“å‰ä¸Šæ¸¸é…ç½®çš„æ¯ä¸ª API å¯†é’¥ã€‚

### 2. éšæœº (random)

åœ¨å½“å‰ä¸Šæ¸¸é…ç½®çš„ API å¯†é’¥ä¸­éšæœºé€‰æ‹©ä¸€ä¸ªä½¿ç”¨ã€‚

### 3. æ•…éšœè½¬ç§» (failover)

æ€»æ˜¯ä¼˜å…ˆä½¿ç”¨å½“å‰ä¸Šæ¸¸é…ç½®çš„ç¬¬ä¸€ä¸ª API å¯†é’¥ã€‚è¿™ç§ç­–ç•¥é€‚ç”¨äºä¸»å¤‡å¯†é’¥åœºæ™¯ã€‚

## ğŸ›¡ï¸ å®‰å…¨ç‰¹æ€§

- API å¯†é’¥å®‰å…¨å­˜å‚¨å’Œç®¡ç†
- CORS è·¨åŸŸè¯·æ±‚æ§åˆ¶
- è¯·æ±‚é¢‘ç‡é™åˆ¶ï¼ˆå¯é€‰ï¼‰
- è¯·æ±‚è¶…æ—¶ä¿æŠ¤
- é”™è¯¯å¤„ç†å’Œæ—¥å¿—è®°å½•

## ğŸš€ éƒ¨ç½²

### æœ¬åœ°å¼€å‘

```bash
# å¼€å‘æ¨¡å¼ï¼ˆçƒ­é‡è½½ï¼‰
pnpm dev:local

# ç”Ÿäº§æ¨¡å¼
pnpm start
```

### Cloudflare Workers éƒ¨ç½²

```bash
# éƒ¨ç½²åˆ° Cloudflare Workers
pnpm deploycf
```

## åœ¨ Claude Code ä¸­ä½¿ç”¨

é…ç½® Claude Code ä½¿ç”¨æœ¬åœ°ä»£ç†ï¼š

```bash
# ç¼–è¾‘ ~/.claude/settings.json
{
  "env": {
    "ANTHROPIC_BASE_URL": "http://localhost:3000",
    "ANTHROPIC_CUSTOM_HEADERS": "x-api-key: your-proxy-access-key",
    "ANTHROPIC_MODEL": "claude-3-5-sonnet-20241022",
    "ANTHROPIC_SMALL_FAST_MODEL": "claude-3-haiku-20240307",
    "API_TIMEOUT_MS": "600000"
  }
}

claude
```

> **é‡è¦è¯´æ˜**: `your-proxy-access-key` æ˜¯ä½ è®¿é—®ä»£ç†æœåŠ¡å™¨çš„æˆæƒå¯†é’¥ï¼Œä¸æ˜¯ä¸Šæ¸¸æœåŠ¡å•†çš„ API keyã€‚è¿™ä¸ª key ç”¨äºéªŒè¯ä½ å¯¹ä»£ç†æœåŠ¡å™¨çš„è®¿é—®æƒé™ã€‚

## â“ å¸¸è§é—®é¢˜è§£ç­” (FAQ)

### Q1: ä»£ç†æœåŠ¡å™¨æ”¯æŒå“ªäº›ä¸Šæ¸¸ AI æœåŠ¡å•†ï¼Ÿ

**A:** ç›®å‰æ”¯æŒä»¥ä¸‹æœåŠ¡å•†ï¼š
- **OpenAI**: ä½¿ç”¨ OpenAI æ ¼å¼çš„ APIï¼ˆå¦‚ OpenAI å®˜æ–¹ã€å„ç§ç¬¬ä¸‰æ–¹ OpenAI å…¼å®¹æœåŠ¡ï¼‰
- **Gemini**: Google çš„ Gemini API
- **Claude**: Anthropic çš„å®˜æ–¹ Claude API
- **è‡ªå®šä¹‰ API**: ä»»ä½•å…¼å®¹ OpenAI æ ¼å¼çš„ç¬¬ä¸‰æ–¹ API

### Q2: å¦‚ä½•å®ç° API å¯†é’¥çš„è´Ÿè½½å‡è¡¡ï¼Ÿ

**A:** ä»£ç†æœåŠ¡å™¨æ”¯æŒä¸‰ç§è´Ÿè½½å‡è¡¡ç­–ç•¥ï¼š

1. **è½®è¯¢ (round-robin)**: æŒ‰é¡ºåºè½®æµä½¿ç”¨æ¯ä¸ª API å¯†é’¥
2. **éšæœº (random)**: éšæœºé€‰æ‹©ä¸€ä¸ª API å¯†é’¥
3. **æ•…éšœè½¬ç§» (failover)**: æ€»æ˜¯ä¼˜å…ˆä½¿ç”¨ç¬¬ä¸€ä¸ªå¯†é’¥

```bash
# è®¾ç½®è´Ÿè½½å‡è¡¡ç­–ç•¥
bun run config balance round-robin
```

### Q3: å¯ä»¥åŒæ—¶é…ç½®å¤šä¸ªä¸Šæ¸¸æœåŠ¡å•†å—ï¼Ÿ

**A:** å¯ä»¥ï¼ä½ å¯ä»¥é…ç½®å¤šä¸ªä¸Šæ¸¸ï¼Œä½†åŒæ—¶åªèƒ½ä½¿ç”¨ä¸€ä¸ªã€‚é€šè¿‡ä»¥ä¸‹å‘½ä»¤åˆ‡æ¢ï¼š

```bash
# æŸ¥çœ‹æ‰€æœ‰ä¸Šæ¸¸
bun run config show

# æŒ‰ç´¢å¼•åˆ‡æ¢
bun run config use 0

# æŒ‰åç§°åˆ‡æ¢
bun run config use openai-main
```

### Q4: ç³»ç»Ÿæ˜¯å¦éœ€è¦å¤–éƒ¨ä¾èµ–ï¼Ÿ

**A:** ä¸éœ€è¦ã€‚ç³»ç»Ÿå·²ç»ç®€åŒ–ï¼Œç§»é™¤äº†Redisä¾èµ–ï¼š
- **APIå¯†é’¥è½®è¯¢**: ä½¿ç”¨å†…å­˜è®¡æ•°å™¨å®ç°
- **é…ç½®ç®¡ç†**: åŸºäºæœ¬åœ°æ–‡ä»¶ï¼Œæ”¯æŒçƒ­é‡è½½
- **éƒ¨ç½²ç®€å•**: æ— éœ€é…ç½®å¤–éƒ¨æ•°æ®åº“æˆ–ç¼“å­˜

### Q5: å¦‚ä½•åœ¨ Claude Code ä¸­ä½¿ç”¨è¿™ä¸ªä»£ç†ï¼Ÿ

**A:** ä¿®æ”¹ Claude Code çš„é…ç½®æ–‡ä»¶ `~/.claude/settings.json`ï¼š

```json
{
  "env": {
    "ANTHROPIC_BASE_URL": "http://localhost:3000",
    "ANTHROPIC_CUSTOM_HEADERS": "x-api-key: your-proxy-access-key",
    "ANTHROPIC_MODEL": "claude-3-5-sonnet-20241022"
  }
}
```

### Q6: æ”¯æŒæµå¼å“åº”å—ï¼Ÿ

**A:** å®Œå…¨æ”¯æŒï¼åœ¨è¯·æ±‚ä¸­æ·»åŠ  `"stream": true` å³å¯ï¼š

```json
{
    "model": "claude-3-5-sonnet-20241022",
    "stream": true,
    "messages": [...]
}
```

### Q7: å¦‚ä½•ç›‘æ§ä»£ç†æœåŠ¡å™¨çš„çŠ¶æ€ï¼Ÿ

**A:** ä½¿ç”¨å¥åº·æ£€æŸ¥ç«¯ç‚¹ï¼š

```bash
curl http://localhost:3000/health
```

å¼€å‘æ¨¡å¼ä¸‹è¿˜æœ‰é¢å¤–çš„ç›‘æ§ç«¯ç‚¹ï¼š

```bash
# å¼€å‘ç¯å¢ƒä¿¡æ¯
curl http://localhost:3000/admin/dev/info

# é‡è½½é…ç½®
curl -X POST http://localhost:3000/admin/config/reload
```

## ğŸ› æ•…éšœæ’é™¤

### å¯åŠ¨é—®é¢˜

#### 1. ç«¯å£è¢«å ç”¨

**ç°è±¡**: `Error: listen EADDRINUSE: address already in use :::3000`

**è§£å†³æ–¹æ¡ˆ**:
```bash
# æŸ¥çœ‹ç«¯å£å ç”¨
lsof -i :3000

# å¼ºåˆ¶ç»ˆæ­¢è¿›ç¨‹
kill -9 <PID>

# æˆ–ä¿®æ”¹ç«¯å£
echo "PORT=3001" >> .env
```

#### 2. é…ç½®æ–‡ä»¶æŸå

**ç°è±¡**: `SyntaxError: Unexpected token in JSON`

**è§£å†³æ–¹æ¡ˆ**:
```bash
# æ£€æŸ¥é…ç½®æ–‡ä»¶è¯­æ³•
cat config.json | python -m json.tool

# é‡æ–°ç”Ÿæˆé…ç½®æ–‡ä»¶
rm config.json
bun run config show
```

### API è°ƒç”¨é—®é¢˜

#### 1. 401 Unauthorized

**å¯èƒ½åŸå› **:
- ä»£ç†è®¿é—®å¯†é’¥é”™è¯¯
- ä¸Šæ¸¸ API å¯†é’¥æ— æ•ˆ

**è§£å†³æ–¹æ¡ˆ**:
```bash
# æ£€æŸ¥ä»£ç†è®¿é—®å¯†é’¥
echo $PROXY_ACCESS_KEY

# æ£€æŸ¥ä¸Šæ¸¸ API å¯†é’¥
bun run config show

# æµ‹è¯•ä¸Šæ¸¸ API å¯†é’¥
curl -H "Authorization: Bearer sk-your-key" https://api.openai.com/v1/models
```

#### 2. 429 Too Many Requests

**å¯èƒ½åŸå› **:
- API å¯†é’¥é…é¢ä¸è¶³
- è¯·æ±‚é¢‘ç‡è¿‡é«˜

**è§£å†³æ–¹æ¡ˆ**:
```bash
# æ·»åŠ æ›´å¤š API å¯†é’¥
bun run config key your-upstream add sk-new-key

# ä¿®æ”¹è´Ÿè½½å‡è¡¡ç­–ç•¥
bun run config balance round-robin
```

#### 3. 500 Internal Server Error

**å¯èƒ½åŸå› **:
- ä¸Šæ¸¸æœåŠ¡ä¸å¯ç”¨
- é…ç½®é”™è¯¯

**è§£å†³æ–¹æ¡ˆ**:
```bash
# æ£€æŸ¥æœåŠ¡å™¨æ—¥å¿—
tail -f server.log

# å¯ç”¨è°ƒè¯•æ¨¡å¼
echo "LOG_LEVEL=debug" >> .env
echo "ENABLE_REQUEST_LOGS=true" >> .env
echo "ENABLE_RESPONSE_LOGS=true" >> .env

# é‡å¯æœåŠ¡å™¨
bun run start
```

### æ€§èƒ½é—®é¢˜

#### 1. å“åº”ç¼“æ…¢

**è§£å†³æ–¹æ¡ˆ**:
```bash
# å¢åŠ å¹¶å‘æ•°
echo "MAX_CONCURRENT_REQUESTS=200" >> .env

# å‡å°‘è¶…æ—¶æ—¶é—´
echo "REQUEST_TIMEOUT=15000" >> .env

# ä½¿ç”¨æ›´è¿‘çš„ä¸Šæ¸¸æœåŠ¡
bun run config show
```

#### 2. å†…å­˜ä½¿ç”¨è¿‡é«˜

**è§£å†³æ–¹æ¡ˆ**:
```bash
# å‡å°‘æ—¥å¿—çº§åˆ«
echo "LOG_LEVEL=error" >> .env
echo "ENABLE_REQUEST_LOGS=false" >> .env
echo "ENABLE_RESPONSE_LOGS=false" >> .env

# é‡å¯æœåŠ¡å™¨
bun run start
```

### è°ƒè¯•æŠ€å·§

#### 1. å¯ç”¨è¯¦ç»†æ—¥å¿—

```bash
# åœ¨ .env æ–‡ä»¶ä¸­è®¾ç½®
LOG_LEVEL=debug
ENABLE_REQUEST_LOGS=true
ENABLE_RESPONSE_LOGS=true
```

#### 2. ä½¿ç”¨å¥åº·æ£€æŸ¥

```bash
# åŸºç¡€å¥åº·æ£€æŸ¥
curl http://localhost:3000/health

# å¼€å‘æ¨¡å¼ä¿¡æ¯
curl http://localhost:3000/admin/dev/info
```

#### 3. æ‰‹åŠ¨æµ‹è¯•ä¸Šæ¸¸ API

```bash
# æµ‹è¯• OpenAI API
curl -X POST https://api.openai.com/v1/chat/completions \
  -H "Authorization: Bearer sk-your-key" \
  -H "Content-Type: application/json" \
  -d '{"model":"gpt-3.5-turbo","messages":[{"role":"user","content":"Hello"}]}'

# æµ‹è¯• Gemini API
curl -X POST https://generativelanguage.googleapis.com/v1beta/models/gemini-pro:generateContent?key=your-key \
  -H "Content-Type: application/json" \
  -d '{"contents":[{"parts":[{"text":"Hello"}]}]}'
```

#### 4. é…ç½®éªŒè¯

```bash
# æŸ¥çœ‹å®Œæ•´é…ç½®
bun run config show

# éªŒè¯é…ç½®æ–‡ä»¶æ ¼å¼
cat config.json | jq .
```

## ğŸ“ è®¸å¯è¯

MIT License

## ğŸ¤ è´¡çŒ®

æ¬¢è¿æäº¤ Issue å’Œ Pull Requestï¼

## ğŸ“ æ”¯æŒ

å¦‚æœ‰é—®é¢˜ï¼Œè¯·æŸ¥çœ‹æ•…éšœæ’é™¤éƒ¨åˆ†æˆ–æäº¤ Issueã€‚
