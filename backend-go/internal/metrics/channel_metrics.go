package metrics

import (
	"crypto/sha256"
	"encoding/hex"
	"log"
	"sort"
	"sync"
	"time"

	"github.com/BenedictKing/claude-proxy/internal/types"
	"github.com/BenedictKing/claude-proxy/internal/utils"
)

// RequestRecord å¸¦æ—¶é—´æˆ³çš„è¯·æ±‚è®°å½•ï¼ˆæ‰©å±•ç‰ˆï¼Œæ”¯æŒ Token å’Œ Cache æ•°æ®ï¼‰
type RequestRecord struct {
	Timestamp                time.Time
	Success                  bool
	InputTokens              int64
	OutputTokens             int64
	CacheCreationInputTokens int64
	CacheReadInputTokens     int64
}

// KeyMetrics å•ä¸ª Key çš„æŒ‡æ ‡ï¼ˆç»‘å®šåˆ° BaseURL + Key ç»„åˆï¼‰
type KeyMetrics struct {
	MetricsKey          string     `json:"metricsKey"`          // hash(baseURL + apiKey)
	BaseURL             string     `json:"baseUrl"`             // ç”¨äºæ˜¾ç¤º
	KeyMask             string     `json:"keyMask"`             // è„±æ•çš„ keyï¼ˆç”¨äºæ˜¾ç¤ºï¼‰
	RequestCount        int64      `json:"requestCount"`        // æ€»è¯·æ±‚æ•°
	SuccessCount        int64      `json:"successCount"`        // æˆåŠŸæ•°
	FailureCount        int64      `json:"failureCount"`        // å¤±è´¥æ•°
	ConsecutiveFailures int64      `json:"consecutiveFailures"` // è¿ç»­å¤±è´¥æ•°
	LastSuccessAt       *time.Time `json:"lastSuccessAt,omitempty"`
	LastFailureAt       *time.Time `json:"lastFailureAt,omitempty"`
	CircuitBrokenAt     *time.Time `json:"circuitBrokenAt,omitempty"` // ç†”æ–­å¼€å§‹æ—¶é—´
	// æ»‘åŠ¨çª—å£è®°å½•ï¼ˆæœ€è¿‘ N æ¬¡è¯·æ±‚çš„ç»“æœï¼‰
	recentResults []bool // true=success, false=failure
	// å¸¦æ—¶é—´æˆ³çš„è¯·æ±‚è®°å½•ï¼ˆç”¨äºåˆ†æ—¶æ®µç»Ÿè®¡ï¼Œä¿ç•™24å°æ—¶ï¼‰
	requestHistory []RequestRecord
}

// ChannelMetrics æ¸ é“èšåˆæŒ‡æ ‡ï¼ˆç”¨äº API è¿”å›ï¼Œå…¼å®¹æ—§ç»“æ„ï¼‰
type ChannelMetrics struct {
	ChannelIndex        int        `json:"channelIndex"`
	RequestCount        int64      `json:"requestCount"`
	SuccessCount        int64      `json:"successCount"`
	FailureCount        int64      `json:"failureCount"`
	ConsecutiveFailures int64      `json:"consecutiveFailures"`
	LastSuccessAt       *time.Time `json:"lastSuccessAt,omitempty"`
	LastFailureAt       *time.Time `json:"lastFailureAt,omitempty"`
	CircuitBrokenAt     *time.Time `json:"circuitBrokenAt,omitempty"`
	// æ»‘åŠ¨çª—å£è®°å½•ï¼ˆå…¼å®¹æ—§ä»£ç ï¼‰
	recentResults []bool
	// å¸¦æ—¶é—´æˆ³çš„è¯·æ±‚è®°å½•
	requestHistory []RequestRecord
}

// TimeWindowStats åˆ†æ—¶æ®µç»Ÿè®¡
type TimeWindowStats struct {
	RequestCount int64   `json:"requestCount"`
	SuccessCount int64   `json:"successCount"`
	FailureCount int64   `json:"failureCount"`
	SuccessRate  float64 `json:"successRate"`
}

// MetricsManager æŒ‡æ ‡ç®¡ç†å™¨
type MetricsManager struct {
	mu                  sync.RWMutex
	keyMetrics          map[string]*KeyMetrics // key: hash(baseURL + apiKey)
	windowSize          int                    // æ»‘åŠ¨çª—å£å¤§å°
	failureThreshold    float64                // å¤±è´¥ç‡é˜ˆå€¼
	circuitRecoveryTime time.Duration          // ç†”æ–­æ¢å¤æ—¶é—´
	stopCh              chan struct{}          // ç”¨äºåœæ­¢æ¸…ç† goroutine

	// æŒä¹…åŒ–å­˜å‚¨ï¼ˆå¯é€‰ï¼‰
	store   PersistenceStore
	apiType string // "messages" æˆ– "responses"
}

// NewMetricsManager åˆ›å»ºæŒ‡æ ‡ç®¡ç†å™¨
func NewMetricsManager() *MetricsManager {
	m := &MetricsManager{
		keyMetrics:          make(map[string]*KeyMetrics),
		windowSize:          10,               // é»˜è®¤åŸºäºæœ€è¿‘ 10 æ¬¡è¯·æ±‚è®¡ç®—å¤±è´¥ç‡
		failureThreshold:    0.5,              // é»˜è®¤ 50% å¤±è´¥ç‡é˜ˆå€¼
		circuitRecoveryTime: 15 * time.Minute, // é»˜è®¤ 15 åˆ†é’Ÿè‡ªåŠ¨æ¢å¤
		stopCh:              make(chan struct{}),
	}
	// å¯åŠ¨åå°ç†”æ–­æ¢å¤ä»»åŠ¡
	go m.cleanupCircuitBreakers()
	return m
}

// NewMetricsManagerWithConfig åˆ›å»ºå¸¦é…ç½®çš„æŒ‡æ ‡ç®¡ç†å™¨
func NewMetricsManagerWithConfig(windowSize int, failureThreshold float64) *MetricsManager {
	if windowSize < 3 {
		windowSize = 3 // æœ€å° 3
	}
	if failureThreshold <= 0 || failureThreshold > 1 {
		failureThreshold = 0.5
	}
	m := &MetricsManager{
		keyMetrics:          make(map[string]*KeyMetrics),
		windowSize:          windowSize,
		failureThreshold:    failureThreshold,
		circuitRecoveryTime: 15 * time.Minute,
		stopCh:              make(chan struct{}),
	}
	// å¯åŠ¨åå°ç†”æ–­æ¢å¤ä»»åŠ¡
	go m.cleanupCircuitBreakers()
	return m
}

// NewMetricsManagerWithPersistence åˆ›å»ºå¸¦æŒä¹…åŒ–çš„æŒ‡æ ‡ç®¡ç†å™¨
func NewMetricsManagerWithPersistence(windowSize int, failureThreshold float64, store PersistenceStore, apiType string) *MetricsManager {
	if windowSize < 3 {
		windowSize = 3
	}
	if failureThreshold <= 0 || failureThreshold > 1 {
		failureThreshold = 0.5
	}
	m := &MetricsManager{
		keyMetrics:          make(map[string]*KeyMetrics),
		windowSize:          windowSize,
		failureThreshold:    failureThreshold,
		circuitRecoveryTime: 15 * time.Minute,
		stopCh:              make(chan struct{}),
		store:               store,
		apiType:             apiType,
	}

	// ä»æŒä¹…åŒ–å­˜å‚¨åŠ è½½å†å²æ•°æ®
	if store != nil {
		if err := m.loadFromStore(); err != nil {
			log.Printf("âš ï¸ [%s] åŠ è½½å†å²æŒ‡æ ‡æ•°æ®å¤±è´¥: %v", apiType, err)
		}
	}

	// å¯åŠ¨åå°ç†”æ–­æ¢å¤ä»»åŠ¡
	go m.cleanupCircuitBreakers()
	return m
}

// loadFromStore ä»æŒä¹…åŒ–å­˜å‚¨åŠ è½½æ•°æ®
func (m *MetricsManager) loadFromStore() error {
	if m.store == nil {
		return nil
	}

	// åŠ è½½æœ€è¿‘ 24 å°æ—¶çš„æ•°æ®
	since := time.Now().Add(-24 * time.Hour)
	records, err := m.store.LoadRecords(since, m.apiType)
	if err != nil {
		return err
	}

	if len(records) == 0 {
		log.Printf("ğŸ“Š [%s] æ— å†å²æŒ‡æ ‡æ•°æ®éœ€è¦åŠ è½½", m.apiType)
		return nil
	}

	m.mu.Lock()
	defer m.mu.Unlock()

	// é‡å»ºå†…å­˜ä¸­çš„ KeyMetrics
	for _, r := range records {
		metrics := m.getOrCreateKeyLocked(r.BaseURL, r.MetricsKey, r.KeyMask)

		// é‡å»ºè¯·æ±‚å†å²
		metrics.requestHistory = append(metrics.requestHistory, RequestRecord{
			Timestamp:                r.Timestamp,
			Success:                  r.Success,
			InputTokens:              r.InputTokens,
			OutputTokens:             r.OutputTokens,
			CacheCreationInputTokens: r.CacheCreationTokens,
			CacheReadInputTokens:     r.CacheReadTokens,
		})

		// æ›´æ–°èšåˆè®¡æ•°
		metrics.RequestCount++
		if r.Success {
			metrics.SuccessCount++
			if metrics.LastSuccessAt == nil || r.Timestamp.After(*metrics.LastSuccessAt) {
				t := r.Timestamp
				metrics.LastSuccessAt = &t
			}
		} else {
			metrics.FailureCount++
			if metrics.LastFailureAt == nil || r.Timestamp.After(*metrics.LastFailureAt) {
				t := r.Timestamp
				metrics.LastFailureAt = &t
			}
		}
	}

	// é‡å»ºæ»‘åŠ¨çª—å£ï¼ˆå–æœ€è¿‘ windowSize æ¡è®°å½•ï¼‰
	for _, metrics := range m.keyMetrics {
		n := len(metrics.requestHistory)
		start := 0
		if n > m.windowSize {
			start = n - m.windowSize
		}
		metrics.recentResults = make([]bool, 0, m.windowSize)
		for i := start; i < n; i++ {
			metrics.recentResults = append(metrics.recentResults, metrics.requestHistory[i].Success)
		}
	}

	log.Printf("âœ… [%s] å·²ä»æŒä¹…åŒ–å­˜å‚¨åŠ è½½ %d æ¡å†å²è®°å½•ï¼Œé‡å»º %d ä¸ª Key æŒ‡æ ‡",
		m.apiType, len(records), len(m.keyMetrics))
	return nil
}

// getOrCreateKeyLocked è·å–æˆ–åˆ›å»º Key æŒ‡æ ‡ï¼ˆç”¨äºåŠ è½½æ—¶ï¼Œå·²çŸ¥ metricsKey å’Œ keyMaskï¼‰
func (m *MetricsManager) getOrCreateKeyLocked(baseURL, metricsKey, keyMask string) *KeyMetrics {
	if metrics, exists := m.keyMetrics[metricsKey]; exists {
		return metrics
	}
	metrics := &KeyMetrics{
		MetricsKey:    metricsKey,
		BaseURL:       baseURL,
		KeyMask:       keyMask,
		recentResults: make([]bool, 0, m.windowSize),
	}
	m.keyMetrics[metricsKey] = metrics
	return metrics
}

// generateMetricsKey ç”ŸæˆæŒ‡æ ‡é”® hash(baseURL + apiKey)
func generateMetricsKey(baseURL, apiKey string) string {
	h := sha256.New()
	h.Write([]byte(baseURL + "|" + apiKey))
	return hex.EncodeToString(h.Sum(nil))[:16] // å–å‰16ä½ä½œä¸ºé”®
}

// getOrCreateKey è·å–æˆ–åˆ›å»º Key æŒ‡æ ‡
func (m *MetricsManager) getOrCreateKey(baseURL, apiKey string) *KeyMetrics {
	metricsKey := generateMetricsKey(baseURL, apiKey)
	if metrics, exists := m.keyMetrics[metricsKey]; exists {
		return metrics
	}
	metrics := &KeyMetrics{
		MetricsKey:    metricsKey,
		BaseURL:       baseURL,
		KeyMask:       utils.MaskAPIKey(apiKey),
		recentResults: make([]bool, 0, m.windowSize),
	}
	m.keyMetrics[metricsKey] = metrics
	return metrics
}

// RecordSuccess è®°å½•æˆåŠŸè¯·æ±‚ï¼ˆæ–°æ–¹æ³•ï¼Œä½¿ç”¨ baseURL + apiKeyï¼‰
func (m *MetricsManager) RecordSuccess(baseURL, apiKey string) {
	m.RecordSuccessWithUsage(baseURL, apiKey, nil)
}

// RecordSuccessWithUsage è®°å½•æˆåŠŸè¯·æ±‚ï¼ˆå¸¦ Usage æ•°æ®ï¼‰
func (m *MetricsManager) RecordSuccessWithUsage(baseURL, apiKey string, usage *types.Usage) {
	m.mu.Lock()
	defer m.mu.Unlock()

	metrics := m.getOrCreateKey(baseURL, apiKey)
	metrics.RequestCount++
	metrics.SuccessCount++
	metrics.ConsecutiveFailures = 0

	now := time.Now()
	metrics.LastSuccessAt = &now

	// æˆåŠŸåæ¸…é™¤ç†”æ–­æ ‡è®°
	if metrics.CircuitBrokenAt != nil {
		metrics.CircuitBrokenAt = nil
		log.Printf("âœ… Key [%s] (%s) å› è¯·æ±‚æˆåŠŸé€€å‡ºç†”æ–­çŠ¶æ€", metrics.KeyMask, metrics.BaseURL)
	}

	// æ›´æ–°æ»‘åŠ¨çª—å£
	m.appendToWindowKey(metrics, true)

	// æå– Token æ•°æ®ï¼ˆå¦‚æœæœ‰ï¼‰
	var inputTokens, outputTokens, cacheCreationTokens, cacheReadTokens int64
	if usage != nil {
		inputTokens = int64(usage.InputTokens)
		outputTokens = int64(usage.OutputTokens)
		cacheCreationTokens = int64(usage.CacheCreationInputTokens)
		cacheReadTokens = int64(usage.CacheReadInputTokens)
	}

	// è®°å½•å¸¦æ—¶é—´æˆ³çš„è¯·æ±‚
	m.appendToHistoryKeyWithUsage(metrics, now, true, inputTokens, outputTokens, cacheCreationTokens, cacheReadTokens)

	// å†™å…¥æŒä¹…åŒ–å­˜å‚¨ï¼ˆå¼‚æ­¥ï¼Œä¸é˜»å¡ï¼‰
	if m.store != nil {
		m.store.AddRecord(PersistentRecord{
			MetricsKey:          metrics.MetricsKey,
			BaseURL:             baseURL,
			KeyMask:             metrics.KeyMask,
			Timestamp:           now,
			Success:             true,
			InputTokens:         inputTokens,
			OutputTokens:        outputTokens,
			CacheCreationTokens: cacheCreationTokens,
			CacheReadTokens:     cacheReadTokens,
			APIType:             m.apiType,
		})
	}
}

// RecordFailure è®°å½•å¤±è´¥è¯·æ±‚ï¼ˆæ–°æ–¹æ³•ï¼Œä½¿ç”¨ baseURL + apiKeyï¼‰
func (m *MetricsManager) RecordFailure(baseURL, apiKey string) {
	m.mu.Lock()
	defer m.mu.Unlock()

	metrics := m.getOrCreateKey(baseURL, apiKey)
	metrics.RequestCount++
	metrics.FailureCount++
	metrics.ConsecutiveFailures++

	now := time.Now()
	metrics.LastFailureAt = &now

	// æ›´æ–°æ»‘åŠ¨çª—å£
	m.appendToWindowKey(metrics, false)

	// æ£€æŸ¥æ˜¯å¦åˆšè¿›å…¥ç†”æ–­çŠ¶æ€
	if metrics.CircuitBrokenAt == nil && m.isKeyCircuitBroken(metrics) {
		metrics.CircuitBrokenAt = &now
		log.Printf("âš¡ Key [%s] (%s) è¿›å…¥ç†”æ–­çŠ¶æ€ï¼ˆå¤±è´¥ç‡: %.1f%%ï¼‰", metrics.KeyMask, metrics.BaseURL, m.calculateKeyFailureRateInternal(metrics)*100)
	}

	// è®°å½•å¸¦æ—¶é—´æˆ³çš„è¯·æ±‚
	m.appendToHistoryKey(metrics, now, false)

	// å†™å…¥æŒä¹…åŒ–å­˜å‚¨ï¼ˆå¼‚æ­¥ï¼Œä¸é˜»å¡ï¼‰
	if m.store != nil {
		m.store.AddRecord(PersistentRecord{
			MetricsKey:          metrics.MetricsKey,
			BaseURL:             baseURL,
			KeyMask:             metrics.KeyMask,
			Timestamp:           now,
			Success:             false,
			InputTokens:         0,
			OutputTokens:        0,
			CacheCreationTokens: 0,
			CacheReadTokens:     0,
			APIType:             m.apiType,
		})
	}
}

// isKeyCircuitBroken åˆ¤æ–­ Key æ˜¯å¦è¾¾åˆ°ç†”æ–­æ¡ä»¶ï¼ˆå†…éƒ¨æ–¹æ³•ï¼Œè°ƒç”¨å‰éœ€æŒæœ‰é”ï¼‰
func (m *MetricsManager) isKeyCircuitBroken(metrics *KeyMetrics) bool {
	// æœ€å°è¯·æ±‚æ•°ä¿æŠ¤ï¼šè‡³å°‘ max(3, windowSize/2) æ¬¡è¯·æ±‚æ‰åˆ¤æ–­ç†”æ–­
	minRequests := max(3, m.windowSize/2)
	if len(metrics.recentResults) < minRequests {
		return false
	}
	return m.calculateKeyFailureRateInternal(metrics) >= m.failureThreshold
}

// calculateKeyFailureRateInternal è®¡ç®— Key å¤±è´¥ç‡ï¼ˆå†…éƒ¨æ–¹æ³•ï¼Œè°ƒç”¨å‰éœ€æŒæœ‰é”ï¼‰
func (m *MetricsManager) calculateKeyFailureRateInternal(metrics *KeyMetrics) float64 {
	if len(metrics.recentResults) == 0 {
		return 0
	}
	failures := 0
	for _, success := range metrics.recentResults {
		if !success {
			failures++
		}
	}
	return float64(failures) / float64(len(metrics.recentResults))
}

// appendToWindowKey å‘ Key æ»‘åŠ¨çª—å£æ·»åŠ è®°å½•
func (m *MetricsManager) appendToWindowKey(metrics *KeyMetrics, success bool) {
	metrics.recentResults = append(metrics.recentResults, success)
	// ä¿æŒçª—å£å¤§å°
	if len(metrics.recentResults) > m.windowSize {
		metrics.recentResults = metrics.recentResults[1:]
	}
}

// appendToHistoryKey å‘ Key å†å²è®°å½•æ·»åŠ è¯·æ±‚ï¼ˆä¿ç•™24å°æ—¶ï¼‰
func (m *MetricsManager) appendToHistoryKey(metrics *KeyMetrics, timestamp time.Time, success bool) {
	m.appendToHistoryKeyWithUsage(metrics, timestamp, success, 0, 0, 0, 0)
}

// appendToHistoryKeyWithUsage å‘ Key å†å²è®°å½•æ·»åŠ è¯·æ±‚ï¼ˆå¸¦ Usage æ•°æ®ï¼‰
func (m *MetricsManager) appendToHistoryKeyWithUsage(metrics *KeyMetrics, timestamp time.Time, success bool, inputTokens, outputTokens, cacheCreationTokens, cacheReadTokens int64) {
	metrics.requestHistory = append(metrics.requestHistory, RequestRecord{
		Timestamp:                timestamp,
		Success:                  success,
		InputTokens:              inputTokens,
		OutputTokens:             outputTokens,
		CacheCreationInputTokens: cacheCreationTokens,
		CacheReadInputTokens:     cacheReadTokens,
	})

	// æ¸…ç†è¶…è¿‡24å°æ—¶çš„è®°å½•
	cutoff := time.Now().Add(-24 * time.Hour)
	newStart := -1
	for i, record := range metrics.requestHistory {
		if record.Timestamp.After(cutoff) {
			newStart = i
			break
		}
	}
	if newStart > 0 {
		metrics.requestHistory = metrics.requestHistory[newStart:]
	} else if newStart == -1 && len(metrics.requestHistory) > 0 {
		// æ‰€æœ‰è®°å½•éƒ½è¿‡æœŸï¼Œæ¸…ç©ºåˆ‡ç‰‡
		metrics.requestHistory = metrics.requestHistory[:0]
	}
}

// IsKeyHealthy åˆ¤æ–­å•ä¸ª Key æ˜¯å¦å¥åº·
func (m *MetricsManager) IsKeyHealthy(baseURL, apiKey string) bool {
	m.mu.RLock()
	defer m.mu.RUnlock()

	metricsKey := generateMetricsKey(baseURL, apiKey)
	metrics, exists := m.keyMetrics[metricsKey]
	if !exists || len(metrics.recentResults) == 0 {
		return true // æ²¡æœ‰è®°å½•ï¼Œé»˜è®¤å¥åº·
	}

	return m.calculateKeyFailureRateInternal(metrics) < m.failureThreshold
}

// IsChannelHealthy åˆ¤æ–­æ¸ é“æ˜¯å¦å¥åº·ï¼ˆåŸºäºå½“å‰æ´»è·ƒ Keys èšåˆè®¡ç®—ï¼‰
// activeKeys: å½“å‰æ¸ é“é…ç½®çš„æ‰€æœ‰æ´»è·ƒ API Keys
func (m *MetricsManager) IsChannelHealthyWithKeys(baseURL string, activeKeys []string) bool {
	if len(activeKeys) == 0 {
		return false // æ²¡æœ‰ Keyï¼Œä¸å¥åº·
	}

	m.mu.RLock()
	defer m.mu.RUnlock()

	// èšåˆæ‰€æœ‰æ´»è·ƒ Key çš„æŒ‡æ ‡
	var totalResults []bool
	for _, apiKey := range activeKeys {
		metricsKey := generateMetricsKey(baseURL, apiKey)
		if metrics, exists := m.keyMetrics[metricsKey]; exists {
			totalResults = append(totalResults, metrics.recentResults...)
		}
	}

	// æ²¡æœ‰ä»»ä½•è®°å½•ï¼Œé»˜è®¤å¥åº·
	if len(totalResults) == 0 {
		return true
	}

	// æœ€å°è¯·æ±‚æ•°ä¿æŠ¤ï¼šè‡³å°‘ max(3, windowSize/2) æ¬¡è¯·æ±‚æ‰åˆ¤æ–­å¥åº·çŠ¶æ€
	minRequests := max(3, m.windowSize/2)
	if len(totalResults) < minRequests {
		return true // è¯·æ±‚æ•°ä¸è¶³ï¼Œé»˜è®¤å¥åº·
	}

	// è®¡ç®—èšåˆå¤±è´¥ç‡
	failures := 0
	for _, success := range totalResults {
		if !success {
			failures++
		}
	}
	failureRate := float64(failures) / float64(len(totalResults))

	return failureRate < m.failureThreshold
}

// CalculateKeyFailureRate è®¡ç®—å•ä¸ª Key çš„å¤±è´¥ç‡
func (m *MetricsManager) CalculateKeyFailureRate(baseURL, apiKey string) float64 {
	m.mu.RLock()
	defer m.mu.RUnlock()

	metricsKey := generateMetricsKey(baseURL, apiKey)
	metrics, exists := m.keyMetrics[metricsKey]
	if !exists || len(metrics.recentResults) == 0 {
		return 0
	}

	return m.calculateKeyFailureRateInternal(metrics)
}

// CalculateChannelFailureRate è®¡ç®—æ¸ é“èšåˆå¤±è´¥ç‡
func (m *MetricsManager) CalculateChannelFailureRate(baseURL string, activeKeys []string) float64 {
	if len(activeKeys) == 0 {
		return 0
	}

	m.mu.RLock()
	defer m.mu.RUnlock()

	var totalResults []bool
	for _, apiKey := range activeKeys {
		metricsKey := generateMetricsKey(baseURL, apiKey)
		if metrics, exists := m.keyMetrics[metricsKey]; exists {
			totalResults = append(totalResults, metrics.recentResults...)
		}
	}

	if len(totalResults) == 0 {
		return 0
	}

	failures := 0
	for _, success := range totalResults {
		if !success {
			failures++
		}
	}

	return float64(failures) / float64(len(totalResults))
}

// GetKeyMetrics è·å–å•ä¸ª Key çš„æŒ‡æ ‡
func (m *MetricsManager) GetKeyMetrics(baseURL, apiKey string) *KeyMetrics {
	m.mu.RLock()
	defer m.mu.RUnlock()

	metricsKey := generateMetricsKey(baseURL, apiKey)
	if metrics, exists := m.keyMetrics[metricsKey]; exists {
		// è¿”å›å‰¯æœ¬
		return &KeyMetrics{
			MetricsKey:          metrics.MetricsKey,
			BaseURL:             metrics.BaseURL,
			KeyMask:             metrics.KeyMask,
			RequestCount:        metrics.RequestCount,
			SuccessCount:        metrics.SuccessCount,
			FailureCount:        metrics.FailureCount,
			ConsecutiveFailures: metrics.ConsecutiveFailures,
			LastSuccessAt:       metrics.LastSuccessAt,
			LastFailureAt:       metrics.LastFailureAt,
			CircuitBrokenAt:     metrics.CircuitBrokenAt,
		}
	}
	return nil
}

// GetChannelAggregatedMetrics è·å–æ¸ é“èšåˆæŒ‡æ ‡ï¼ˆåŸºäºæ´»è·ƒ Keysï¼‰
func (m *MetricsManager) GetChannelAggregatedMetrics(channelIndex int, baseURL string, activeKeys []string) *ChannelMetrics {
	m.mu.RLock()
	defer m.mu.RUnlock()

	aggregated := &ChannelMetrics{
		ChannelIndex: channelIndex,
	}

	var latestSuccess, latestFailure, latestCircuitBroken *time.Time
	var maxConsecutiveFailures int64

	for _, apiKey := range activeKeys {
		metricsKey := generateMetricsKey(baseURL, apiKey)
		if metrics, exists := m.keyMetrics[metricsKey]; exists {
			aggregated.RequestCount += metrics.RequestCount
			aggregated.SuccessCount += metrics.SuccessCount
			aggregated.FailureCount += metrics.FailureCount
			if metrics.ConsecutiveFailures > maxConsecutiveFailures {
				maxConsecutiveFailures = metrics.ConsecutiveFailures
			}
			aggregated.recentResults = append(aggregated.recentResults, metrics.recentResults...)
			aggregated.requestHistory = append(aggregated.requestHistory, metrics.requestHistory...)

			// å–æœ€æ–°çš„æ—¶é—´æˆ³
			if metrics.LastSuccessAt != nil && (latestSuccess == nil || metrics.LastSuccessAt.After(*latestSuccess)) {
				latestSuccess = metrics.LastSuccessAt
			}
			if metrics.LastFailureAt != nil && (latestFailure == nil || metrics.LastFailureAt.After(*latestFailure)) {
				latestFailure = metrics.LastFailureAt
			}
			if metrics.CircuitBrokenAt != nil && (latestCircuitBroken == nil || metrics.CircuitBrokenAt.After(*latestCircuitBroken)) {
				latestCircuitBroken = metrics.CircuitBrokenAt
			}
		}
	}

	aggregated.LastSuccessAt = latestSuccess
	aggregated.LastFailureAt = latestFailure
	aggregated.CircuitBrokenAt = latestCircuitBroken
	aggregated.ConsecutiveFailures = maxConsecutiveFailures

	return aggregated
}

// KeyUsageInfo Key ä½¿ç”¨ä¿¡æ¯ï¼ˆç”¨äºæ’åºç­›é€‰ï¼‰
type KeyUsageInfo struct {
	APIKey       string
	KeyMask      string
	RequestCount int64
	LastUsedAt   *time.Time
}

// GetChannelKeyUsageInfo è·å–æ¸ é“ä¸‹æ‰€æœ‰ Key çš„ä½¿ç”¨ä¿¡æ¯ï¼ˆç”¨äºæ’åºç­›é€‰ï¼‰
// è¿”å›çš„ keys å·²æŒ‰æœ€è¿‘ä½¿ç”¨æ—¶é—´æ’åº
func (m *MetricsManager) GetChannelKeyUsageInfo(baseURL string, apiKeys []string) []KeyUsageInfo {
	m.mu.RLock()
	defer m.mu.RUnlock()

	infos := make([]KeyUsageInfo, 0, len(apiKeys))

	for _, apiKey := range apiKeys {
		metricsKey := generateMetricsKey(baseURL, apiKey)
		metrics, exists := m.keyMetrics[metricsKey]

		var keyMask string
		var requestCount int64
		var lastUsedAt *time.Time

		if exists {
			keyMask = metrics.KeyMask
			requestCount = metrics.RequestCount
			lastUsedAt = metrics.LastSuccessAt
			if lastUsedAt == nil {
				lastUsedAt = metrics.LastFailureAt
			}
		} else {
			// Key è¿˜æ²¡æœ‰æŒ‡æ ‡è®°å½•ï¼Œä½¿ç”¨é»˜è®¤è„±æ•
			keyMask = utils.MaskAPIKey(apiKey)
			requestCount = 0
		}

		infos = append(infos, KeyUsageInfo{
			APIKey:       apiKey,
			KeyMask:      keyMask,
			RequestCount: requestCount,
			LastUsedAt:   lastUsedAt,
		})
	}

	// æŒ‰æœ€è¿‘ä½¿ç”¨æ—¶é—´æ’åºï¼ˆæœ€è¿‘çš„åœ¨å‰é¢ï¼‰
	sort.Slice(infos, func(i, j int) bool {
		if infos[i].LastUsedAt == nil && infos[j].LastUsedAt == nil {
			return infos[i].RequestCount > infos[j].RequestCount // éƒ½æœªä½¿ç”¨æ—¶ï¼ŒæŒ‰è®¿é—®é‡æ’åº
		}
		if infos[i].LastUsedAt == nil {
			return false // i æœªä½¿ç”¨ï¼Œæ’åé¢
		}
		if infos[j].LastUsedAt == nil {
			return true // j æœªä½¿ç”¨ï¼Œi æ’å‰é¢
		}
		return infos[i].LastUsedAt.After(*infos[j].LastUsedAt)
	})

	return infos
}

// SelectTopKeys ç­›é€‰å±•ç¤ºçš„ Key
// ç­–ç•¥ï¼šå…ˆå–æœ€è¿‘ä½¿ç”¨çš„ 5 ä¸ªï¼Œå†ä»å…¶ä»– Key ä¸­æŒ‰è®¿é—®é‡è¡¥å…¨åˆ° 10 ä¸ª
func SelectTopKeys(infos []KeyUsageInfo, maxDisplay int) []KeyUsageInfo {
	if len(infos) <= maxDisplay {
		return infos
	}

	// åˆ†ç¦»ï¼šæœ€è¿‘ä½¿ç”¨çš„å’Œæœªä½¿ç”¨çš„
	var recentKeys []KeyUsageInfo
	var otherKeys []KeyUsageInfo

	for i, info := range infos {
		if i < 5 {
			recentKeys = append(recentKeys, info)
		} else {
			otherKeys = append(otherKeys, info)
		}
	}

	// å…¶ä»– Key æŒ‰è®¿é—®é‡æ’åºï¼ˆé™åºï¼‰
	sort.Slice(otherKeys, func(i, j int) bool {
		return otherKeys[i].RequestCount > otherKeys[j].RequestCount
	})

	// è¡¥å…¨åˆ° maxDisplay ä¸ª
	result := make([]KeyUsageInfo, 0, maxDisplay)
	result = append(result, recentKeys...)

	needCount := maxDisplay - len(recentKeys)
	if needCount > 0 && len(otherKeys) > 0 {
		if len(otherKeys) > needCount {
			otherKeys = otherKeys[:needCount]
		}
		result = append(result, otherKeys...)
	}

	return result
}

// GetAllKeyMetrics è·å–æ‰€æœ‰ Key çš„æŒ‡æ ‡
func (m *MetricsManager) GetAllKeyMetrics() []*KeyMetrics {
	m.mu.RLock()
	defer m.mu.RUnlock()

	result := make([]*KeyMetrics, 0, len(m.keyMetrics))
	for _, metrics := range m.keyMetrics {
		result = append(result, &KeyMetrics{
			MetricsKey:          metrics.MetricsKey,
			BaseURL:             metrics.BaseURL,
			KeyMask:             metrics.KeyMask,
			RequestCount:        metrics.RequestCount,
			SuccessCount:        metrics.SuccessCount,
			FailureCount:        metrics.FailureCount,
			ConsecutiveFailures: metrics.ConsecutiveFailures,
			LastSuccessAt:       metrics.LastSuccessAt,
			LastFailureAt:       metrics.LastFailureAt,
			CircuitBrokenAt:     metrics.CircuitBrokenAt,
		})
	}
	return result
}

// GetTimeWindowStatsForKey è·å–æŒ‡å®š Key åœ¨æ—¶é—´çª—å£å†…çš„ç»Ÿè®¡
func (m *MetricsManager) GetTimeWindowStatsForKey(baseURL, apiKey string, duration time.Duration) TimeWindowStats {
	m.mu.RLock()
	defer m.mu.RUnlock()

	metricsKey := generateMetricsKey(baseURL, apiKey)
	metrics, exists := m.keyMetrics[metricsKey]
	if !exists {
		return TimeWindowStats{SuccessRate: 100}
	}

	cutoff := time.Now().Add(-duration)
	var requestCount, successCount, failureCount int64

	for _, record := range metrics.requestHistory {
		if record.Timestamp.After(cutoff) {
			requestCount++
			if record.Success {
				successCount++
			} else {
				failureCount++
			}
		}
	}

	successRate := float64(100)
	if requestCount > 0 {
		successRate = float64(successCount) / float64(requestCount) * 100
	}

	return TimeWindowStats{
		RequestCount: requestCount,
		SuccessCount: successCount,
		FailureCount: failureCount,
		SuccessRate:  successRate,
	}
}

// GetAllTimeWindowStatsForKey è·å–å•ä¸ª Key æ‰€æœ‰æ—¶é—´çª—å£çš„ç»Ÿè®¡
func (m *MetricsManager) GetAllTimeWindowStatsForKey(baseURL, apiKey string) map[string]TimeWindowStats {
	return map[string]TimeWindowStats{
		"15m": m.GetTimeWindowStatsForKey(baseURL, apiKey, 15*time.Minute),
		"1h":  m.GetTimeWindowStatsForKey(baseURL, apiKey, 1*time.Hour),
		"6h":  m.GetTimeWindowStatsForKey(baseURL, apiKey, 6*time.Hour),
		"24h": m.GetTimeWindowStatsForKey(baseURL, apiKey, 24*time.Hour),
	}
}

// ResetKey é‡ç½®å•ä¸ª Key çš„æŒ‡æ ‡
func (m *MetricsManager) ResetKey(baseURL, apiKey string) {
	m.mu.Lock()
	defer m.mu.Unlock()

	metricsKey := generateMetricsKey(baseURL, apiKey)
	if metrics, exists := m.keyMetrics[metricsKey]; exists {
		// å®Œå…¨é‡ç½®æ‰€æœ‰å­—æ®µ
		metrics.RequestCount = 0
		metrics.SuccessCount = 0
		metrics.FailureCount = 0
		metrics.ConsecutiveFailures = 0
		metrics.LastSuccessAt = nil
		metrics.LastFailureAt = nil
		metrics.CircuitBrokenAt = nil
		metrics.recentResults = make([]bool, 0, m.windowSize)
		metrics.requestHistory = nil
		log.Printf("ğŸ”„ Key [%s] (%s) æŒ‡æ ‡å·²å®Œå…¨é‡ç½®", metrics.KeyMask, metrics.BaseURL)
	}
}

// ResetAll é‡ç½®æ‰€æœ‰æŒ‡æ ‡
func (m *MetricsManager) ResetAll() {
	m.mu.Lock()
	defer m.mu.Unlock()

	m.keyMetrics = make(map[string]*KeyMetrics)
}

// Stop åœæ­¢åå°æ¸…ç†ä»»åŠ¡
func (m *MetricsManager) Stop() {
	close(m.stopCh)
}

// cleanupCircuitBreakers åå°ä»»åŠ¡ï¼šå®šæœŸæ£€æŸ¥å¹¶æ¢å¤è¶…æ—¶çš„ç†”æ–­ Keyï¼Œæ¸…ç†è¿‡æœŸæŒ‡æ ‡
func (m *MetricsManager) cleanupCircuitBreakers() {
	ticker := time.NewTicker(1 * time.Minute)
	defer ticker.Stop()

	// æ¯å°æ—¶æ¸…ç†ä¸€æ¬¡è¿‡æœŸ Key
	cleanupTicker := time.NewTicker(1 * time.Hour)
	defer cleanupTicker.Stop()

	for {
		select {
		case <-ticker.C:
			m.recoverExpiredCircuitBreakers()
		case <-cleanupTicker.C:
			m.cleanupStaleKeys()
		case <-m.stopCh:
			return
		}
	}
}

// recoverExpiredCircuitBreakers æ¢å¤è¶…æ—¶çš„ç†”æ–­ Key
func (m *MetricsManager) recoverExpiredCircuitBreakers() {
	m.mu.Lock()
	defer m.mu.Unlock()

	now := time.Now()
	for _, metrics := range m.keyMetrics {
		if metrics.CircuitBrokenAt != nil {
			elapsed := now.Sub(*metrics.CircuitBrokenAt)
			if elapsed > m.circuitRecoveryTime {
				// é‡ç½®ç†”æ–­çŠ¶æ€
				metrics.ConsecutiveFailures = 0
				metrics.recentResults = make([]bool, 0, m.windowSize)
				metrics.CircuitBrokenAt = nil
				log.Printf("âœ… Key [%s] (%s) ç†”æ–­è‡ªåŠ¨æ¢å¤ï¼ˆå·²è¶…è¿‡ %vï¼‰", metrics.KeyMask, metrics.BaseURL, m.circuitRecoveryTime)
			}
		}
	}
}

// cleanupStaleKeys æ¸…ç†è¿‡æœŸçš„ Key æŒ‡æ ‡ï¼ˆè¶…è¿‡ 48 å°æ—¶æ— æ´»åŠ¨ï¼‰
func (m *MetricsManager) cleanupStaleKeys() {
	m.mu.Lock()
	defer m.mu.Unlock()

	now := time.Now()
	staleThreshold := 48 * time.Hour
	var removed []string

	for key, metrics := range m.keyMetrics {
		// åˆ¤æ–­æœ€åæ´»åŠ¨æ—¶é—´
		var lastActivity time.Time
		if metrics.LastSuccessAt != nil {
			lastActivity = *metrics.LastSuccessAt
		}
		if metrics.LastFailureAt != nil && metrics.LastFailureAt.After(lastActivity) {
			lastActivity = *metrics.LastFailureAt
		}

		// å¦‚æœä»æœªæœ‰æ´»åŠ¨æˆ–è¶…è¿‡é˜ˆå€¼ï¼Œåˆ é™¤
		if lastActivity.IsZero() || now.Sub(lastActivity) > staleThreshold {
			delete(m.keyMetrics, key)
			removed = append(removed, metrics.KeyMask)
		}
	}

	if len(removed) > 0 {
		log.Printf("ğŸ§¹ æ¸…ç†äº† %d ä¸ªè¿‡æœŸ Key æŒ‡æ ‡: %v", len(removed), removed)
	}
}

// GetCircuitRecoveryTime è·å–ç†”æ–­æ¢å¤æ—¶é—´
func (m *MetricsManager) GetCircuitRecoveryTime() time.Duration {
	return m.circuitRecoveryTime
}

// GetFailureThreshold è·å–å¤±è´¥ç‡é˜ˆå€¼
func (m *MetricsManager) GetFailureThreshold() float64 {
	return m.failureThreshold
}

// GetWindowSize è·å–æ»‘åŠ¨çª—å£å¤§å°
func (m *MetricsManager) GetWindowSize() int {
	return m.windowSize
}

// ============ å…¼å®¹æ—§ API çš„æ–¹æ³•ï¼ˆåŸºäº channelIndexï¼Œéœ€è¦è°ƒç”¨æ–¹æä¾› baseURL å’Œ keysï¼‰============

// MetricsResponse API å“åº”ç»“æ„
type MetricsResponse struct {
	ChannelIndex        int                        `json:"channelIndex"`
	RequestCount        int64                      `json:"requestCount"`
	SuccessCount        int64                      `json:"successCount"`
	FailureCount        int64                      `json:"failureCount"`
	SuccessRate         float64                    `json:"successRate"`
	ErrorRate           float64                    `json:"errorRate"`
	ConsecutiveFailures int64                      `json:"consecutiveFailures"`
	Latency             int64                      `json:"latency"`
	LastSuccessAt       *string                    `json:"lastSuccessAt,omitempty"`
	LastFailureAt       *string                    `json:"lastFailureAt,omitempty"`
	CircuitBrokenAt     *string                    `json:"circuitBrokenAt,omitempty"`
	TimeWindows         map[string]TimeWindowStats `json:"timeWindows,omitempty"`
	KeyMetrics          []*KeyMetricsResponse      `json:"keyMetrics,omitempty"` // å„ Key çš„è¯¦ç»†æŒ‡æ ‡
}

// KeyMetricsResponse å•ä¸ª Key çš„ API å“åº”
type KeyMetricsResponse struct {
	KeyMask             string  `json:"keyMask"`
	RequestCount        int64   `json:"requestCount"`
	SuccessCount        int64   `json:"successCount"`
	FailureCount        int64   `json:"failureCount"`
	SuccessRate         float64 `json:"successRate"`
	ConsecutiveFailures int64   `json:"consecutiveFailures"`
	CircuitBroken       bool    `json:"circuitBroken"`
}

// ToResponse è½¬æ¢ä¸º API å“åº”æ ¼å¼ï¼ˆéœ€è¦æä¾› baseURL å’Œ activeKeysï¼‰
func (m *MetricsManager) ToResponse(channelIndex int, baseURL string, activeKeys []string, latency int64) *MetricsResponse {
	m.mu.RLock()
	defer m.mu.RUnlock()

	resp := &MetricsResponse{
		ChannelIndex: channelIndex,
		Latency:      latency,
	}

	if len(activeKeys) == 0 {
		resp.SuccessRate = 100
		resp.ErrorRate = 0
		return resp
	}

	var keyResponses []*KeyMetricsResponse
	var latestSuccess, latestFailure, latestCircuitBroken *time.Time
	var totalResults []bool
	var maxConsecutiveFailures int64

	for _, apiKey := range activeKeys {
		metricsKey := generateMetricsKey(baseURL, apiKey)
		if metrics, exists := m.keyMetrics[metricsKey]; exists {
			resp.RequestCount += metrics.RequestCount
			resp.SuccessCount += metrics.SuccessCount
			resp.FailureCount += metrics.FailureCount
			if metrics.ConsecutiveFailures > maxConsecutiveFailures {
				maxConsecutiveFailures = metrics.ConsecutiveFailures
			}
			totalResults = append(totalResults, metrics.recentResults...)

			// å–æœ€æ–°çš„æ—¶é—´æˆ³
			if metrics.LastSuccessAt != nil && (latestSuccess == nil || metrics.LastSuccessAt.After(*latestSuccess)) {
				latestSuccess = metrics.LastSuccessAt
			}
			if metrics.LastFailureAt != nil && (latestFailure == nil || metrics.LastFailureAt.After(*latestFailure)) {
				latestFailure = metrics.LastFailureAt
			}
			if metrics.CircuitBrokenAt != nil && (latestCircuitBroken == nil || metrics.CircuitBrokenAt.After(*latestCircuitBroken)) {
				latestCircuitBroken = metrics.CircuitBrokenAt
			}

			// å•ä¸ª Key çš„æŒ‡æ ‡
			keySuccessRate := float64(100)
			if metrics.RequestCount > 0 {
				keySuccessRate = float64(metrics.SuccessCount) / float64(metrics.RequestCount) * 100
			}
			keyResponses = append(keyResponses, &KeyMetricsResponse{
				KeyMask:             metrics.KeyMask,
				RequestCount:        metrics.RequestCount,
				SuccessCount:        metrics.SuccessCount,
				FailureCount:        metrics.FailureCount,
				SuccessRate:         keySuccessRate,
				ConsecutiveFailures: metrics.ConsecutiveFailures,
				CircuitBroken:       metrics.CircuitBrokenAt != nil,
			})
		}
	}

	// è®¡ç®—èšåˆå¤±è´¥ç‡
	resp.ConsecutiveFailures = maxConsecutiveFailures

	if len(totalResults) > 0 {
		failures := 0
		for _, success := range totalResults {
			if !success {
				failures++
			}
		}
		failureRate := float64(failures) / float64(len(totalResults))
		resp.SuccessRate = (1 - failureRate) * 100
		resp.ErrorRate = failureRate * 100
	} else {
		resp.SuccessRate = 100
		resp.ErrorRate = 0
	}

	if latestSuccess != nil {
		t := latestSuccess.Format(time.RFC3339)
		resp.LastSuccessAt = &t
	}
	if latestFailure != nil {
		t := latestFailure.Format(time.RFC3339)
		resp.LastFailureAt = &t
	}
	if latestCircuitBroken != nil {
		t := latestCircuitBroken.Format(time.RFC3339)
		resp.CircuitBrokenAt = &t
	}

	resp.KeyMetrics = keyResponses

	// è®¡ç®—èšåˆçš„æ—¶é—´çª—å£ç»Ÿè®¡
	resp.TimeWindows = m.calculateAggregatedTimeWindowsInternal(baseURL, activeKeys)

	return resp
}

// calculateAggregatedTimeWindowsInternal è®¡ç®—èšåˆçš„æ—¶é—´çª—å£ç»Ÿè®¡ï¼ˆå†…éƒ¨æ–¹æ³•ï¼Œè°ƒç”¨å‰éœ€æŒæœ‰é”ï¼‰
func (m *MetricsManager) calculateAggregatedTimeWindowsInternal(baseURL string, activeKeys []string) map[string]TimeWindowStats {
	windows := map[string]time.Duration{
		"15m": 15 * time.Minute,
		"1h":  1 * time.Hour,
		"6h":  6 * time.Hour,
		"24h": 24 * time.Hour,
	}

	result := make(map[string]TimeWindowStats)
	now := time.Now()

	for label, duration := range windows {
		cutoff := now.Add(-duration)
		var requestCount, successCount, failureCount int64

		for _, apiKey := range activeKeys {
			metricsKey := generateMetricsKey(baseURL, apiKey)
			if metrics, exists := m.keyMetrics[metricsKey]; exists {
				for _, record := range metrics.requestHistory {
					if record.Timestamp.After(cutoff) {
						requestCount++
						if record.Success {
							successCount++
						} else {
							failureCount++
						}
					}
				}
			}
		}

		successRate := float64(100)
		if requestCount > 0 {
			successRate = float64(successCount) / float64(requestCount) * 100
		}

		result[label] = TimeWindowStats{
			RequestCount: requestCount,
			SuccessCount: successCount,
			FailureCount: failureCount,
			SuccessRate:  successRate,
		}
	}

	return result
}

// ============ åºŸå¼ƒçš„æ—§æ–¹æ³•ï¼ˆä¿ç•™ç­¾åä»¥ä¾¿ç¼–è¯‘ï¼Œä½†æ ‡è®°ä¸ºåºŸå¼ƒï¼‰============

// Deprecated: ä½¿ç”¨ IsChannelHealthyWithKeys ä»£æ›¿
// IsChannelHealthy åˆ¤æ–­æ¸ é“æ˜¯å¦å¥åº·ï¼ˆæ—§æ–¹æ³•ï¼Œä¸å†ä½¿ç”¨ channelIndexï¼‰
// æ­¤æ–¹æ³•ä¿ç•™æ˜¯ä¸ºäº†å…¼å®¹ï¼Œä½†å§‹ç»ˆè¿”å› trueï¼Œè°ƒç”¨æ–¹åº”è¿ç§»åˆ°æ–°æ–¹æ³•
func (m *MetricsManager) IsChannelHealthy(channelIndex int) bool {
	log.Printf("âš ï¸ è­¦å‘Š: è°ƒç”¨äº†åºŸå¼ƒçš„ IsChannelHealthy(channelIndex=%d)ï¼Œè¯·è¿ç§»åˆ° IsChannelHealthyWithKeys", channelIndex)
	return true // é»˜è®¤å¥åº·ï¼Œé¿å…å½±å“ç°æœ‰é€»è¾‘
}

// Deprecated: ä½¿ç”¨ CalculateChannelFailureRate ä»£æ›¿
func (m *MetricsManager) CalculateFailureRate(channelIndex int) float64 {
	return 0
}

// Deprecated: ä½¿ç”¨ CalculateChannelFailureRate ä»£æ›¿
func (m *MetricsManager) CalculateSuccessRate(channelIndex int) float64 {
	return 1
}

// Deprecated: ä½¿ç”¨ ResetKey ä»£æ›¿
func (m *MetricsManager) Reset(channelIndex int) {
	log.Printf("âš ï¸ è­¦å‘Š: è°ƒç”¨äº†åºŸå¼ƒçš„ Reset(channelIndex=%d)ï¼Œè¯·è¿ç§»åˆ° ResetKey", channelIndex)
}

// Deprecated: ä½¿ç”¨ GetChannelAggregatedMetrics ä»£æ›¿
func (m *MetricsManager) GetMetrics(channelIndex int) *ChannelMetrics {
	return nil
}

// Deprecated: ä½¿ç”¨ GetAllKeyMetrics ä»£æ›¿
func (m *MetricsManager) GetAllMetrics() []*ChannelMetrics {
	return nil
}

// Deprecated: ä½¿ç”¨ GetTimeWindowStatsForKey ä»£æ›¿
func (m *MetricsManager) GetTimeWindowStats(channelIndex int, duration time.Duration) TimeWindowStats {
	return TimeWindowStats{SuccessRate: 100}
}

// Deprecated: ä½¿ç”¨ GetAllTimeWindowStatsForKey ä»£æ›¿
func (m *MetricsManager) GetAllTimeWindowStats(channelIndex int) map[string]TimeWindowStats {
	return map[string]TimeWindowStats{
		"15m": {SuccessRate: 100},
		"1h":  {SuccessRate: 100},
		"6h":  {SuccessRate: 100},
		"24h": {SuccessRate: 100},
	}
}

// Deprecated: ä½¿ç”¨æ–°çš„ ShouldSuspendKey ä»£æ›¿
func (m *MetricsManager) ShouldSuspend(channelIndex int) bool {
	return false
}

// ShouldSuspendKey åˆ¤æ–­å•ä¸ª Key æ˜¯å¦åº”è¯¥ç†”æ–­
func (m *MetricsManager) ShouldSuspendKey(baseURL, apiKey string) bool {
	m.mu.RLock()
	defer m.mu.RUnlock()

	metricsKey := generateMetricsKey(baseURL, apiKey)
	metrics, exists := m.keyMetrics[metricsKey]
	if !exists {
		return false
	}

	// æœ€å°è¯·æ±‚æ•°ä¿æŠ¤ï¼šè‡³å°‘ max(3, windowSize/2) æ¬¡è¯·æ±‚æ‰åˆ¤æ–­
	minRequests := max(3, m.windowSize/2)
	if len(metrics.recentResults) < minRequests {
		return false
	}

	return m.calculateKeyFailureRateInternal(metrics) >= m.failureThreshold
}

// ============ å†å²æ•°æ®æŸ¥è¯¢æ–¹æ³•ï¼ˆç”¨äºå›¾è¡¨å¯è§†åŒ–ï¼‰============

// HistoryDataPoint å†å²æ•°æ®ç‚¹ï¼ˆç”¨äºæ—¶é—´åºåˆ—å›¾è¡¨ï¼‰
type HistoryDataPoint struct {
	Timestamp    time.Time `json:"timestamp"`
	RequestCount int64     `json:"requestCount"`
	SuccessCount int64     `json:"successCount"`
	FailureCount int64     `json:"failureCount"`
	SuccessRate  float64   `json:"successRate"`
}

// KeyHistoryDataPoint Key çº§åˆ«å†å²æ•°æ®ç‚¹ï¼ˆåŒ…å« Token å’Œ Cache æ•°æ®ï¼‰
type KeyHistoryDataPoint struct {
	Timestamp                time.Time `json:"timestamp"`
	RequestCount             int64     `json:"requestCount"`
	SuccessCount             int64     `json:"successCount"`
	FailureCount             int64     `json:"failureCount"`
	SuccessRate              float64   `json:"successRate"`
	InputTokens              int64     `json:"inputTokens"`
	OutputTokens             int64     `json:"outputTokens"`
	CacheCreationInputTokens int64     `json:"cacheCreationTokens"`
	CacheReadInputTokens     int64     `json:"cacheReadTokens"`
}

// GetHistoricalStats è·å–å†å²ç»Ÿè®¡æ•°æ®ï¼ˆæŒ‰æ—¶é—´é—´éš”èšåˆï¼‰
// duration: æŸ¥è¯¢æ—¶é—´èŒƒå›´ (å¦‚ 1h, 6h, 24h)
// interval: èšåˆé—´éš” (å¦‚ 5m, 15m, 1h)
func (m *MetricsManager) GetHistoricalStats(baseURL string, activeKeys []string, duration, interval time.Duration) []HistoryDataPoint {
	// å‚æ•°éªŒè¯
	if interval <= 0 || duration <= 0 {
		return []HistoryDataPoint{}
	}

	m.mu.RLock()
	defer m.mu.RUnlock()

	now := time.Now()
	// æ—¶é—´å¯¹é½åˆ° interval è¾¹ç•Œ
	startTime := now.Add(-duration).Truncate(interval)
	// endTime å»¶ä¼¸ä¸€ä¸ª intervalï¼Œç¡®ä¿å½“å‰æ—¶é—´æ®µçš„è¯·æ±‚ä¹Ÿè¢«åŒ…å«
	endTime := now.Truncate(interval).Add(interval)

	// è®¡ç®—éœ€è¦å¤šå°‘ä¸ªæ•°æ®ç‚¹ï¼ˆ+1 ç”¨äºåŒ…å«å»¶ä¼¸çš„å½“å‰æ—¶é—´æ®µï¼‰
	numPoints := int(duration / interval)
	if numPoints <= 0 {
		numPoints = 1
	}
	numPoints++ // é¢å¤–çš„ä¸€ä¸ªæ¡¶ç”¨äºå½“å‰æ—¶é—´æ®µ

	// ä½¿ç”¨ map æŒ‰æ—¶é—´åˆ†æ¡¶ï¼Œä¼˜åŒ–æ€§èƒ½ï¼šO(records) è€Œä¸æ˜¯ O(records * numPoints)
	buckets := make(map[int64]*bucketData)
	for i := 0; i < numPoints; i++ {
		buckets[int64(i)] = &bucketData{}
	}

	// æ”¶é›†æ‰€æœ‰ç›¸å…³ Key çš„è¯·æ±‚å†å²å¹¶æ”¾å…¥å¯¹åº”æ¡¶
	for _, apiKey := range activeKeys {
		metricsKey := generateMetricsKey(baseURL, apiKey)
		if metrics, exists := m.keyMetrics[metricsKey]; exists {
			for _, record := range metrics.requestHistory {
				// ä½¿ç”¨ Before(endTime) æ’é™¤æ°å¥½è½åœ¨ endTime çš„è®°å½•ï¼Œé¿å… offset è¶Šç•Œ
				if record.Timestamp.After(startTime) && record.Timestamp.Before(endTime) {
					// è®¡ç®—è®°å½•åº”è¯¥å±äºå“ªä¸ªæ¡¶
					offset := int64(record.Timestamp.Sub(startTime) / interval)
					if offset >= 0 && offset < int64(numPoints) {
						b := buckets[offset]
						b.requestCount++
						if record.Success {
							b.successCount++
						} else {
							b.failureCount++
						}
					}
				}
			}
		}
	}

	// æ„å»ºç»“æœ
	result := make([]HistoryDataPoint, numPoints)
	for i := 0; i < numPoints; i++ {
		b := buckets[int64(i)]
		// ç©ºæ¡¶æˆåŠŸç‡é»˜è®¤ä¸º 0ï¼Œé¿å…è¯¯å¯¼ï¼ˆ100% æš—ç¤ºå®Œç¾æˆåŠŸï¼‰
		successRate := float64(0)
		if b.requestCount > 0 {
			successRate = float64(b.successCount) / float64(b.requestCount) * 100
		}
		result[i] = HistoryDataPoint{
			Timestamp:    startTime.Add(time.Duration(i+1) * interval),
			RequestCount: b.requestCount,
			SuccessCount: b.successCount,
			FailureCount: b.failureCount,
			SuccessRate:  successRate,
		}
	}

	return result
}

// bucketData ç”¨äºæ—¶é—´åˆ†æ¡¶çš„è¾…åŠ©ç»“æ„
type bucketData struct {
	requestCount int64
	successCount int64
	failureCount int64
}

// GetAllKeysHistoricalStats è·å–æ‰€æœ‰ Key çš„å†å²ç»Ÿè®¡ï¼ˆä¸åŒºåˆ†æ¸ é“ï¼‰
func (m *MetricsManager) GetAllKeysHistoricalStats(duration, interval time.Duration) []HistoryDataPoint {
	// å‚æ•°éªŒè¯
	if interval <= 0 || duration <= 0 {
		return []HistoryDataPoint{}
	}

	m.mu.RLock()
	defer m.mu.RUnlock()

	now := time.Now()
	// æ—¶é—´å¯¹é½åˆ° interval è¾¹ç•Œ
	startTime := now.Add(-duration).Truncate(interval)
	// endTime å»¶ä¼¸ä¸€ä¸ª intervalï¼Œç¡®ä¿å½“å‰æ—¶é—´æ®µçš„è¯·æ±‚ä¹Ÿè¢«åŒ…å«
	endTime := now.Truncate(interval).Add(interval)

	numPoints := int(duration / interval)
	if numPoints <= 0 {
		numPoints = 1
	}
	numPoints++ // é¢å¤–çš„ä¸€ä¸ªæ¡¶ç”¨äºå½“å‰æ—¶é—´æ®µ

	// ä½¿ç”¨ map æŒ‰æ—¶é—´åˆ†æ¡¶ï¼Œä¼˜åŒ–æ€§èƒ½
	buckets := make(map[int64]*bucketData)
	for i := 0; i < numPoints; i++ {
		buckets[int64(i)] = &bucketData{}
	}

	// æ”¶é›†æ‰€æœ‰ Key çš„è¯·æ±‚å†å²å¹¶æ”¾å…¥å¯¹åº”æ¡¶
	for _, metrics := range m.keyMetrics {
		for _, record := range metrics.requestHistory {
			// ä½¿ç”¨ Before(endTime) æ’é™¤æ°å¥½è½åœ¨ endTime çš„è®°å½•ï¼Œé¿å… offset è¶Šç•Œ
			if record.Timestamp.After(startTime) && record.Timestamp.Before(endTime) {
				offset := int64(record.Timestamp.Sub(startTime) / interval)
				if offset >= 0 && offset < int64(numPoints) {
					b := buckets[offset]
					b.requestCount++
					if record.Success {
						b.successCount++
					} else {
						b.failureCount++
					}
				}
			}
		}
	}

	// æ„å»ºç»“æœ
	result := make([]HistoryDataPoint, numPoints)
	for i := 0; i < numPoints; i++ {
		b := buckets[int64(i)]
		// ç©ºæ¡¶æˆåŠŸç‡é»˜è®¤ä¸º 0ï¼Œé¿å…è¯¯å¯¼ï¼ˆ100% æš—ç¤ºå®Œç¾æˆåŠŸï¼‰
		successRate := float64(0)
		if b.requestCount > 0 {
			successRate = float64(b.successCount) / float64(b.requestCount) * 100
		}
		result[i] = HistoryDataPoint{
			Timestamp:    startTime.Add(time.Duration(i+1) * interval),
			RequestCount: b.requestCount,
			SuccessCount: b.successCount,
			FailureCount: b.failureCount,
			SuccessRate:  successRate,
		}
	}

	return result
}

// GetKeyHistoricalStats è·å–å•ä¸ª Key çš„å†å²ç»Ÿè®¡æ•°æ®ï¼ˆåŒ…å« Token å’Œ Cache æ•°æ®ï¼‰
func (m *MetricsManager) GetKeyHistoricalStats(baseURL, apiKey string, duration, interval time.Duration) []KeyHistoryDataPoint {
	// å‚æ•°éªŒè¯
	if interval <= 0 || duration <= 0 {
		return []KeyHistoryDataPoint{}
	}

	m.mu.RLock()
	defer m.mu.RUnlock()

	now := time.Now()
	// æ—¶é—´å¯¹é½åˆ° interval è¾¹ç•Œ
	startTime := now.Add(-duration).Truncate(interval)
	// endTime å»¶ä¼¸ä¸€ä¸ª intervalï¼Œç¡®ä¿å½“å‰æ—¶é—´æ®µçš„è¯·æ±‚ä¹Ÿè¢«åŒ…å«
	endTime := now.Truncate(interval).Add(interval)

	numPoints := int(duration / interval)
	if numPoints <= 0 {
		numPoints = 1
	}
	numPoints++ // é¢å¤–çš„ä¸€ä¸ªæ¡¶ç”¨äºå½“å‰æ—¶é—´æ®µ

	// ä½¿ç”¨ map æŒ‰æ—¶é—´åˆ†æ¡¶
	buckets := make(map[int64]*keyBucketData)
	for i := 0; i < numPoints; i++ {
		buckets[int64(i)] = &keyBucketData{}
	}

	// è·å– Key çš„æŒ‡æ ‡
	metricsKey := generateMetricsKey(baseURL, apiKey)
	metrics, exists := m.keyMetrics[metricsKey]
	if !exists {
		// Key ä¸å­˜åœ¨ï¼Œè¿”å›ç©ºæ•°æ®ç‚¹
		result := make([]KeyHistoryDataPoint, numPoints)
		for i := 0; i < numPoints; i++ {
			result[i] = KeyHistoryDataPoint{
				Timestamp: startTime.Add(time.Duration(i+1) * interval),
			}
		}
		return result
	}

	// æ”¶é›†è¯¥ Key çš„è¯·æ±‚å†å²å¹¶æ”¾å…¥å¯¹åº”æ¡¶
	for _, record := range metrics.requestHistory {
		// ä½¿ç”¨ Before(endTime) æ’é™¤æ°å¥½è½åœ¨ endTime çš„è®°å½•ï¼Œé¿å… offset è¶Šç•Œ
		if record.Timestamp.After(startTime) && record.Timestamp.Before(endTime) {
			offset := int64(record.Timestamp.Sub(startTime) / interval)
			if offset >= 0 && offset < int64(numPoints) {
				b := buckets[offset]
				b.requestCount++
				if record.Success {
					b.successCount++
				} else {
					b.failureCount++
				}
				// ç´¯åŠ  Token æ•°æ®
				b.inputTokens += record.InputTokens
				b.outputTokens += record.OutputTokens
				b.cacheCreationTokens += record.CacheCreationInputTokens
				b.cacheReadTokens += record.CacheReadInputTokens
			}
		}
	}

	// æ„å»ºç»“æœ
	result := make([]KeyHistoryDataPoint, numPoints)
	for i := 0; i < numPoints; i++ {
		b := buckets[int64(i)]
		// ç©ºæ¡¶æˆåŠŸç‡é»˜è®¤ä¸º 0ï¼Œé¿å…è¯¯å¯¼ï¼ˆ100% æš—ç¤ºå®Œç¾æˆåŠŸï¼‰
		successRate := float64(0)
		if b.requestCount > 0 {
			successRate = float64(b.successCount) / float64(b.requestCount) * 100
		}
		result[i] = KeyHistoryDataPoint{
			Timestamp:                startTime.Add(time.Duration(i+1) * interval),
			RequestCount:             b.requestCount,
			SuccessCount:             b.successCount,
			FailureCount:             b.failureCount,
			SuccessRate:              successRate,
			InputTokens:              b.inputTokens,
			OutputTokens:             b.outputTokens,
			CacheCreationInputTokens: b.cacheCreationTokens,
			CacheReadInputTokens:     b.cacheReadTokens,
		}
	}

	return result
}

// keyBucketData Key çº§åˆ«æ—¶é—´åˆ†æ¡¶çš„è¾…åŠ©ç»“æ„ï¼ˆåŒ…å« Token æ•°æ®ï¼‰
type keyBucketData struct {
	requestCount        int64
	successCount        int64
	failureCount        int64
	inputTokens         int64
	outputTokens        int64
	cacheCreationTokens int64
	cacheReadTokens     int64
}
