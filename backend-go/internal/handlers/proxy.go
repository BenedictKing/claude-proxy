package handlers

import (
	"bytes"
	"encoding/json"
	"fmt"
	"io"
	"log"
	"net/http"
	"strings"
	"time"

	"github.com/BenedictKing/claude-proxy/internal/config"
	"github.com/BenedictKing/claude-proxy/internal/httpclient"
	"github.com/BenedictKing/claude-proxy/internal/middleware"
	"github.com/BenedictKing/claude-proxy/internal/providers"
	"github.com/BenedictKing/claude-proxy/internal/scheduler"
	"github.com/BenedictKing/claude-proxy/internal/types"
	"github.com/BenedictKing/claude-proxy/internal/utils"
	"github.com/gin-gonic/gin"
)

// ProxyHandler ä»£ç†å¤„ç†å™¨
// æ”¯æŒå¤šæ¸ é“è°ƒåº¦ï¼šå½“é…ç½®å¤šä¸ªæ¸ é“æ—¶è‡ªåŠ¨å¯ç”¨
func ProxyHandler(envCfg *config.EnvConfig, cfgManager *config.ConfigManager, channelScheduler *scheduler.ChannelScheduler) gin.HandlerFunc {
	return gin.HandlerFunc(func(c *gin.Context) {
		// å…ˆè¿›è¡Œè®¤è¯
		middleware.ProxyAuthMiddleware(envCfg)(c)
		if c.IsAborted() {
			return
		}

		startTime := time.Now()

		// è¯»å–åŸå§‹è¯·æ±‚ä½“
		bodyBytes, err := io.ReadAll(c.Request.Body)
		if err != nil {
			c.JSON(400, gin.H{"error": "Failed to read request body"})
			return
		}
		// æ¢å¤è¯·æ±‚ä½“ä¾›åç»­ä½¿ç”¨
		c.Request.Body = io.NopCloser(bytes.NewReader(bodyBytes))

		// claudeReq å˜é‡ç”¨äºåˆ¤æ–­æ˜¯å¦æµå¼è¯·æ±‚å’Œæå– user_id
		var claudeReq types.ClaudeRequest
		if len(bodyBytes) > 0 {
			_ = json.Unmarshal(bodyBytes, &claudeReq)
		}

		// æå– user_id ç”¨äº Trace äº²å’Œæ€§
		userID := extractUserID(bodyBytes)

		// æ£€æŸ¥æ˜¯å¦ä¸ºå¤šæ¸ é“æ¨¡å¼
		isMultiChannel := channelScheduler.IsMultiChannelMode(false)

		if isMultiChannel {
			// å¤šæ¸ é“æ¨¡å¼ï¼šä½¿ç”¨è°ƒåº¦å™¨
			handleMultiChannelProxy(c, envCfg, cfgManager, channelScheduler, bodyBytes, claudeReq, userID, startTime)
		} else {
			// å•æ¸ é“æ¨¡å¼ï¼šä½¿ç”¨ç°æœ‰é€»è¾‘ï¼ˆä¹Ÿè®°å½•æŒ‡æ ‡ï¼‰
			handleSingleChannelProxy(c, envCfg, cfgManager, channelScheduler, bodyBytes, claudeReq, startTime)
		}
	})
}

// extractUserID ä»è¯·æ±‚ä½“ä¸­æå– user_id
func extractUserID(bodyBytes []byte) string {
	var req struct {
		Metadata struct {
			UserID string `json:"user_id"`
		} `json:"metadata"`
	}
	if err := json.Unmarshal(bodyBytes, &req); err == nil {
		return req.Metadata.UserID
	}
	return ""
}

// handleMultiChannelProxy å¤„ç†å¤šæ¸ é“ä»£ç†è¯·æ±‚
func handleMultiChannelProxy(
	c *gin.Context,
	envCfg *config.EnvConfig,
	cfgManager *config.ConfigManager,
	channelScheduler *scheduler.ChannelScheduler,
	bodyBytes []byte,
	claudeReq types.ClaudeRequest,
	userID string,
	startTime time.Time,
) {
	failedChannels := make(map[int]bool)
	var lastError error
	var lastFailoverError *struct {
		Status int
		Body   []byte
	}

	// è·å–æ´»è·ƒæ¸ é“æ•°é‡ä½œä¸ºæœ€å¤§é‡è¯•æ¬¡æ•°
	maxChannelAttempts := channelScheduler.GetActiveChannelCount(false)

	for channelAttempt := 0; channelAttempt < maxChannelAttempts; channelAttempt++ {
		// ä½¿ç”¨è°ƒåº¦å™¨é€‰æ‹©æ¸ é“
		selection, err := channelScheduler.SelectChannel(c.Request.Context(), userID, failedChannels, false)
		if err != nil {
			lastError = err
			break
		}

		upstream := selection.Upstream
		channelIndex := selection.ChannelIndex

		if envCfg.ShouldLog("info") {
			log.Printf("ğŸ¯ [å¤šæ¸ é“] é€‰æ‹©æ¸ é“: [%d] %s (åŸå› : %s, å°è¯• %d/%d)",
				channelIndex, upstream.Name, selection.Reason, channelAttempt+1, maxChannelAttempts)
		}

		// å°è¯•ä½¿ç”¨è¯¥æ¸ é“çš„æ‰€æœ‰ keyï¼Œè¿”å›æˆåŠŸä½¿ç”¨çš„ key
		success, successKey, failoverErr := tryChannelWithAllKeys(c, envCfg, cfgManager, channelScheduler, upstream, bodyBytes, claudeReq, startTime, false)

		if success {
			// è®°å½•æˆåŠŸçš„ keyï¼Œæ›´æ–° Trace äº²å’Œ
			if successKey != "" {
				channelScheduler.RecordSuccess(upstream.BaseURL, successKey, false)
			}
			channelScheduler.SetTraceAffinity(userID, channelIndex)
			return
		}

		// æ¸ é“æ‰€æœ‰ key éƒ½å¤±è´¥ï¼Œæ ‡è®°æ¸ é“å¤±è´¥
		failedChannels[channelIndex] = true

		if failoverErr != nil {
			lastFailoverError = failoverErr
			lastError = fmt.Errorf("æ¸ é“ [%d] %s å¤±è´¥", channelIndex, upstream.Name)
		}

		log.Printf("âš ï¸ [å¤šæ¸ é“] æ¸ é“ [%d] %s æ‰€æœ‰å¯†é’¥éƒ½å¤±è´¥ï¼Œå°è¯•ä¸‹ä¸€ä¸ªæ¸ é“", channelIndex, upstream.Name)
	}

	// æ‰€æœ‰æ¸ é“éƒ½å¤±è´¥
	log.Printf("ğŸ’¥ [å¤šæ¸ é“] æ‰€æœ‰æ¸ é“éƒ½å¤±è´¥äº†")

	if lastFailoverError != nil {
		status := lastFailoverError.Status
		if status == 0 {
			status = 503
		}
		var errBody map[string]interface{}
		if err := json.Unmarshal(lastFailoverError.Body, &errBody); err == nil {
			c.JSON(status, errBody)
		} else {
			c.JSON(status, gin.H{"error": string(lastFailoverError.Body)})
		}
	} else {
		errMsg := "æ‰€æœ‰æ¸ é“éƒ½ä¸å¯ç”¨"
		if lastError != nil {
			errMsg = lastError.Error()
		}
		c.JSON(503, gin.H{
			"error":   "æ‰€æœ‰æ¸ é“éƒ½ä¸å¯ç”¨",
			"details": errMsg,
		})
	}
}

// tryChannelWithAllKeys å°è¯•ä½¿ç”¨æ¸ é“çš„æ‰€æœ‰å¯†é’¥
// è¿”å› (success bool, successKey string, lastFailoverError *struct{Status int; Body []byte})
func tryChannelWithAllKeys(
	c *gin.Context,
	envCfg *config.EnvConfig,
	cfgManager *config.ConfigManager,
	channelScheduler *scheduler.ChannelScheduler,
	upstream *config.UpstreamConfig,
	bodyBytes []byte,
	claudeReq types.ClaudeRequest,
	startTime time.Time,
	isResponses bool,
) (bool, string, *struct {
	Status int
	Body   []byte
}) {
	if len(upstream.APIKeys) == 0 {
		return false, "", nil
	}

	provider := providers.GetProvider(upstream.ServiceType)
	if provider == nil {
		return false, "", nil
	}

	// è·å–æŒ‡æ ‡ç®¡ç†å™¨ç”¨äºæ£€æŸ¥ç†”æ–­çŠ¶æ€
	metricsManager := channelScheduler.GetMessagesMetricsManager()
	if isResponses {
		metricsManager = channelScheduler.GetResponsesMetricsManager()
	}

	maxRetries := len(upstream.APIKeys)
	failedKeys := make(map[string]bool)
	var lastFailoverError *struct {
		Status int
		Body   []byte
	}
	deprioritizeCandidates := make(map[string]bool)

	for attempt := 0; attempt < maxRetries; attempt++ {
		// æ¢å¤è¯·æ±‚ä½“
		c.Request.Body = io.NopCloser(bytes.NewReader(bodyBytes))

		apiKey, err := cfgManager.GetNextAPIKey(upstream, failedKeys)
		if err != nil {
			break
		}

		// æ£€æŸ¥è¯¥ Key æ˜¯å¦å¤„äºç†”æ–­çŠ¶æ€ï¼Œè·³è¿‡ç†”æ–­çš„ Key
		if metricsManager.ShouldSuspendKey(upstream.BaseURL, apiKey) {
			failedKeys[apiKey] = true
			log.Printf("âš¡ è·³è¿‡ç†”æ–­ä¸­çš„ Key: %s", maskAPIKey(apiKey))
			continue
		}

		if envCfg.ShouldLog("info") {
			log.Printf("ğŸ”‘ ä½¿ç”¨APIå¯†é’¥: %s (å°è¯• %d/%d)", maskAPIKey(apiKey), attempt+1, maxRetries)
		}

		// è½¬æ¢è¯·æ±‚
		providerReq, _, err := provider.ConvertToProviderRequest(c, upstream, apiKey)
		if err != nil {
			failedKeys[apiKey] = true
			// è®°å½•è¯¥ key å¤±è´¥
			channelScheduler.RecordFailure(upstream.BaseURL, apiKey, isResponses)
			continue
		}

		// å‘é€è¯·æ±‚
		resp, err := sendRequest(providerReq, upstream, envCfg, claudeReq.Stream)
		if err != nil {
			failedKeys[apiKey] = true
			cfgManager.MarkKeyAsFailed(apiKey)
			// è®°å½•è¯¥ key å¤±è´¥
			channelScheduler.RecordFailure(upstream.BaseURL, apiKey, isResponses)
			log.Printf("âš ï¸ APIå¯†é’¥å¤±è´¥: %v", err)
			continue
		}

		// æ£€æŸ¥å“åº”çŠ¶æ€
		if resp.StatusCode < 200 || resp.StatusCode >= 300 {
			respBodyBytes, _ := io.ReadAll(resp.Body)
			resp.Body.Close()
			respBodyBytes = utils.DecompressGzipIfNeeded(resp, respBodyBytes)

			shouldFailover, isQuotaRelated := shouldRetryWithNextKey(resp.StatusCode, respBodyBytes)
			if shouldFailover {
				failedKeys[apiKey] = true
				cfgManager.MarkKeyAsFailed(apiKey)
				// è®°å½•è¯¥ key å¤±è´¥
				channelScheduler.RecordFailure(upstream.BaseURL, apiKey, isResponses)
				log.Printf("âš ï¸ APIå¯†é’¥å¤±è´¥ (çŠ¶æ€: %d)ï¼Œå°è¯•ä¸‹ä¸€ä¸ªå¯†é’¥", resp.StatusCode)

				lastFailoverError = &struct {
					Status int
					Body   []byte
				}{
					Status: resp.StatusCode,
					Body:   respBodyBytes,
				}

				if isQuotaRelated {
					deprioritizeCandidates[apiKey] = true
				}
				continue
			}

			// é failover é”™è¯¯ï¼Œç›´æ¥è¿”å›ï¼ˆè¯·æ±‚å·²å¤„ç†ä½†ä¸ç®—æˆåŠŸï¼‰
			c.Data(resp.StatusCode, "application/json", respBodyBytes)
			return true, "", nil // è¿”å› true è¡¨ç¤ºè¯·æ±‚å·²å¤„ç†ï¼Œä½† successKey ä¸ºç©ºè¡¨ç¤ºä¸è®°å½•æˆåŠŸ
		}

		// å¤„ç†æˆåŠŸå“åº”
		if len(deprioritizeCandidates) > 0 {
			for key := range deprioritizeCandidates {
				_ = cfgManager.DeprioritizeAPIKey(key)
			}
		}

		if claudeReq.Stream {
			handleStreamResponse(c, resp, provider, envCfg, startTime, upstream, bodyBytes)
		} else {
			handleNormalResponse(c, resp, provider, envCfg, startTime, bodyBytes)
		}
		return true, apiKey, nil
	}

	return false, "", lastFailoverError
}

// handleSingleChannelProxy å¤„ç†å•æ¸ é“ä»£ç†è¯·æ±‚ï¼ˆç°æœ‰é€»è¾‘ï¼‰
func handleSingleChannelProxy(
	c *gin.Context,
	envCfg *config.EnvConfig,
	cfgManager *config.ConfigManager,
	channelScheduler *scheduler.ChannelScheduler,
	bodyBytes []byte,
	claudeReq types.ClaudeRequest,
	startTime time.Time,
) {
	// è·å–å½“å‰ä¸Šæ¸¸é…ç½®
	upstream, err := cfgManager.GetCurrentUpstream()
	if err != nil {
		c.JSON(503, gin.H{
			"error": "æœªé…ç½®ä»»ä½•æ¸ é“ï¼Œè¯·å…ˆåœ¨ç®¡ç†ç•Œé¢æ·»åŠ æ¸ é“",
			"code":  "NO_UPSTREAM",
		})
		return
	}

	if len(upstream.APIKeys) == 0 {
		c.JSON(503, gin.H{
			"error": fmt.Sprintf("å½“å‰æ¸ é“ \"%s\" æœªé…ç½®APIå¯†é’¥", upstream.Name),
			"code":  "NO_API_KEYS",
		})
		return
	}

	// è·å–æä¾›å•†
	provider := providers.GetProvider(upstream.ServiceType)
	if provider == nil {
		c.JSON(400, gin.H{"error": "Unsupported service type"})
		return
	}

	// å®ç° failover é‡è¯•é€»è¾‘
	maxRetries := len(upstream.APIKeys)
	failedKeys := make(map[string]bool)
	var lastError error
	var lastOriginalBodyBytes []byte
	var lastFailoverError *struct {
		Status int
		Body   []byte
	}
	deprioritizeCandidates := make(map[string]bool)

	// è·å–æŒ‡æ ‡ç®¡ç†å™¨ç”¨äºæ£€æŸ¥ç†”æ–­çŠ¶æ€
	metricsManager := channelScheduler.GetMessagesMetricsManager()

	for attempt := 0; attempt < maxRetries; attempt++ {
		// æ¢å¤è¯·æ±‚ä½“
		c.Request.Body = io.NopCloser(bytes.NewReader(bodyBytes))

		apiKey, err := cfgManager.GetNextAPIKey(upstream, failedKeys)
		if err != nil {
			lastError = err
			break
		}

		// æ£€æŸ¥è¯¥ Key æ˜¯å¦å¤„äºç†”æ–­çŠ¶æ€ï¼Œè·³è¿‡ç†”æ–­çš„ Key
		if metricsManager.ShouldSuspendKey(upstream.BaseURL, apiKey) {
			failedKeys[apiKey] = true
			log.Printf("âš¡ è·³è¿‡ç†”æ–­ä¸­çš„ Key: %s", maskAPIKey(apiKey))
			continue
		}

		if envCfg.ShouldLog("info") {
			log.Printf("ğŸ¯ ä½¿ç”¨ä¸Šæ¸¸: %s - %s (å°è¯• %d/%d)", upstream.Name, upstream.BaseURL, attempt+1, maxRetries)
			log.Printf("ğŸ”‘ ä½¿ç”¨APIå¯†é’¥: %s", maskAPIKey(apiKey))
		}

		// è½¬æ¢è¯·æ±‚
		providerReq, originalBodyBytes, err := provider.ConvertToProviderRequest(c, upstream, apiKey)
		if err != nil {
			lastError = err
			failedKeys[apiKey] = true
			channelScheduler.RecordFailure(upstream.BaseURL, apiKey, false)
			if originalBodyBytes != nil {
				lastOriginalBodyBytes = originalBodyBytes
			}
			continue
		}
		lastOriginalBodyBytes = originalBodyBytes

		// è¯·æ±‚æ—¥å¿—è®°å½•
		if envCfg.EnableRequestLogs {
			log.Printf("ğŸ“¥ æ”¶åˆ°è¯·æ±‚: %s %s", c.Request.Method, c.Request.URL.Path)
			if envCfg.IsDevelopment() {
				logBody := lastOriginalBodyBytes
				if len(logBody) == 0 && c.Request.Body != nil {
					bodyFromContext, _ := io.ReadAll(c.Request.Body)
					c.Request.Body = io.NopCloser(bytes.NewReader(bodyFromContext))
					logBody = bodyFromContext
				}
				formattedBody := utils.FormatJSONBytesForLog(logBody, 500)
				log.Printf("ğŸ“„ åŸå§‹è¯·æ±‚ä½“:\n%s", formattedBody)

				sanitizedHeaders := make(map[string]string)
				for key, values := range c.Request.Header {
					if len(values) > 0 {
						sanitizedHeaders[key] = values[0]
					}
				}
				maskedHeaders := utils.MaskSensitiveHeaders(sanitizedHeaders)
				headersJSON, _ := json.MarshalIndent(maskedHeaders, "", "  ")
				log.Printf("ğŸ“¥ åŸå§‹è¯·æ±‚å¤´:\n%s", string(headersJSON))
			}
		}

		// å‘é€è¯·æ±‚
		resp, err := sendRequest(providerReq, upstream, envCfg, claudeReq.Stream)
		if err != nil {
			lastError = err
			failedKeys[apiKey] = true
			cfgManager.MarkKeyAsFailed(apiKey)
			channelScheduler.RecordFailure(upstream.BaseURL, apiKey, false)
			log.Printf("âš ï¸ APIå¯†é’¥å¤±è´¥: %v", err)
			continue
		}

		// æ£€æŸ¥å“åº”çŠ¶æ€
		if resp.StatusCode < 200 || resp.StatusCode >= 300 {
			respBodyBytes, _ := io.ReadAll(resp.Body)
			resp.Body.Close()
			respBodyBytes = utils.DecompressGzipIfNeeded(resp, respBodyBytes)

			shouldFailover, isQuotaRelated := shouldRetryWithNextKey(resp.StatusCode, respBodyBytes)
			if shouldFailover {
				lastError = fmt.Errorf("ä¸Šæ¸¸é”™è¯¯: %d", resp.StatusCode)
				failedKeys[apiKey] = true
				cfgManager.MarkKeyAsFailed(apiKey)
				channelScheduler.RecordFailure(upstream.BaseURL, apiKey, false)

				log.Printf("âš ï¸ APIå¯†é’¥å¤±è´¥ (çŠ¶æ€: %d)ï¼Œå°è¯•ä¸‹ä¸€ä¸ªå¯†é’¥", resp.StatusCode)
				if envCfg.EnableResponseLogs && envCfg.IsDevelopment() {
					formattedBody := utils.FormatJSONBytesForLog(respBodyBytes, 500)
					log.Printf("ğŸ“¦ å¤±è´¥åŸå› :\n%s", formattedBody)
				} else if envCfg.EnableResponseLogs {
					log.Printf("å¤±è´¥åŸå› : %s", string(respBodyBytes))
				}

				lastFailoverError = &struct {
					Status int
					Body   []byte
				}{
					Status: resp.StatusCode,
					Body:   respBodyBytes,
				}

				if isQuotaRelated {
					deprioritizeCandidates[apiKey] = true
				}
				continue
			}

			// é failover é”™è¯¯
			if envCfg.EnableResponseLogs {
				log.Printf("âš ï¸ ä¸Šæ¸¸è¿”å›é”™è¯¯: %d", resp.StatusCode)
				if envCfg.IsDevelopment() {
					formattedBody := utils.FormatJSONBytesForLog(respBodyBytes, 500)
					log.Printf("ğŸ“¦ é”™è¯¯å“åº”ä½“:\n%s", formattedBody)

					respHeaders := make(map[string]string)
					for key, values := range resp.Header {
						if len(values) > 0 {
							respHeaders[key] = values[0]
						}
					}
					respHeadersJSON, _ := json.MarshalIndent(respHeaders, "", "  ")
					log.Printf("ğŸ“‹ é”™è¯¯å“åº”å¤´:\n%s", string(respHeadersJSON))
				}
			}
			c.Data(resp.StatusCode, "application/json", respBodyBytes)
			return
		}

		// å¤„ç†æˆåŠŸå“åº”
		channelScheduler.RecordSuccess(upstream.BaseURL, apiKey, false)

		if len(deprioritizeCandidates) > 0 {
			for key := range deprioritizeCandidates {
				if err := cfgManager.DeprioritizeAPIKey(key); err != nil {
					log.Printf("âš ï¸ å¯†é’¥é™çº§å¤±è´¥: %v", err)
				}
			}
		}

		if claudeReq.Stream {
			handleStreamResponse(c, resp, provider, envCfg, startTime, upstream, bodyBytes)
		} else {
			handleNormalResponse(c, resp, provider, envCfg, startTime, bodyBytes)
		}
		return
	}

	// æ‰€æœ‰å¯†é’¥éƒ½å¤±è´¥äº†
	log.Printf("ğŸ’¥ æ‰€æœ‰APIå¯†é’¥éƒ½å¤±è´¥äº†")

	if lastFailoverError != nil {
		status := lastFailoverError.Status
		if status == 0 {
			status = 500
		}
		var errBody map[string]interface{}
		if err := json.Unmarshal(lastFailoverError.Body, &errBody); err == nil {
			c.JSON(status, errBody)
		} else {
			c.JSON(status, gin.H{"error": string(lastFailoverError.Body)})
		}
	} else {
		errMsg := "æœªçŸ¥é”™è¯¯"
		if lastError != nil {
			errMsg = lastError.Error()
		}
		c.JSON(500, gin.H{
			"error":   "æ‰€æœ‰ä¸Šæ¸¸APIå¯†é’¥éƒ½ä¸å¯ç”¨",
			"details": errMsg,
		})
	}
}

// sendRequest å‘é€HTTPè¯·æ±‚
func sendRequest(req *http.Request, upstream *config.UpstreamConfig, envCfg *config.EnvConfig, isStream bool) (*http.Response, error) {
	// ä½¿ç”¨å…¨å±€å®¢æˆ·ç«¯ç®¡ç†å™¨
	clientManager := httpclient.GetManager()

	var client *http.Client
	if isStream {
		// æµå¼è¯·æ±‚ï¼šä½¿ç”¨æ— è¶…æ—¶çš„å®¢æˆ·ç«¯
		client = clientManager.GetStreamClient(upstream.InsecureSkipVerify)
	} else {
		// æ™®é€šè¯·æ±‚ï¼šä½¿ç”¨æœ‰è¶…æ—¶çš„å®¢æˆ·ç«¯
		timeout := time.Duration(envCfg.RequestTimeout) * time.Millisecond
		client = clientManager.GetStandardClient(timeout, upstream.InsecureSkipVerify)
	}

	if upstream.InsecureSkipVerify && envCfg.EnableRequestLogs {
		log.Printf("âš ï¸ æ­£åœ¨è·³è¿‡å¯¹ %s çš„TLSè¯ä¹¦éªŒè¯", req.URL.String())
	}

	if envCfg.EnableRequestLogs {
		log.Printf("ğŸŒ å®é™…è¯·æ±‚URL: %s", req.URL.String())
		log.Printf("ğŸ“¤ è¯·æ±‚æ–¹æ³•: %s", req.Method)
		if envCfg.IsDevelopment() {
			// å¯¹è¯·æ±‚å¤´åšæ•æ„Ÿä¿¡æ¯è„±æ•
			reqHeaders := make(map[string]string)
			for key, values := range req.Header {
				if len(values) > 0 {
					reqHeaders[key] = values[0]
				}
			}
			maskedReqHeaders := utils.MaskSensitiveHeaders(reqHeaders)
			reqHeadersJSON, _ := json.MarshalIndent(maskedReqHeaders, "", "  ")
			log.Printf("ğŸ“‹ å®é™…è¯·æ±‚å¤´:\n%s", string(reqHeadersJSON))

			if req.Body != nil {
				// è¯»å–è¯·æ±‚ä½“ç”¨äºæ—¥å¿—
				bodyBytes, err := io.ReadAll(req.Body)
				if err == nil {
					// æ¢å¤è¯·æ±‚ä½“
					req.Body = io.NopCloser(bytes.NewReader(bodyBytes))

					// ä½¿ç”¨æ™ºèƒ½æˆªæ–­å’Œç®€åŒ–å‡½æ•°ï¼ˆä¸TSç‰ˆæœ¬å¯¹é½ï¼‰
					formattedBody := utils.FormatJSONBytesForLog(bodyBytes, 500)
					log.Printf("ğŸ“¦ å®é™…è¯·æ±‚ä½“:\n%s", formattedBody)
				}
			}
		}
	}

	return client.Do(req)
}

// handleNormalResponse å¤„ç†éæµå¼å“åº”
func handleNormalResponse(c *gin.Context, resp *http.Response, provider providers.Provider, envCfg *config.EnvConfig, startTime time.Time, requestBody []byte) {
	defer resp.Body.Close()

	bodyBytes, err := io.ReadAll(resp.Body)
	if err != nil {
		c.JSON(500, gin.H{"error": "Failed to read response"})
		return
	}

	if envCfg.EnableResponseLogs {
		responseTime := time.Since(startTime).Milliseconds()
		log.Printf("â±ï¸ å“åº”å®Œæˆ: %dms, çŠ¶æ€: %d", responseTime, resp.StatusCode)
		if envCfg.IsDevelopment() {
			// å“åº”å¤´(ä¸éœ€è¦è„±æ•)
			respHeaders := make(map[string]string)
			for key, values := range resp.Header {
				if len(values) > 0 {
					respHeaders[key] = values[0]
				}
			}
			respHeadersJSON, _ := json.MarshalIndent(respHeaders, "", "  ")
			log.Printf("ğŸ“‹ å“åº”å¤´:\n%s", string(respHeadersJSON))

			// ä½¿ç”¨æ™ºèƒ½æˆªæ–­ï¼ˆä¸TSç‰ˆæœ¬å¯¹é½ï¼‰
			formattedBody := utils.FormatJSONBytesForLog(bodyBytes, 500)
			log.Printf("ğŸ“¦ å“åº”ä½“:\n%s", formattedBody)
		}
	}

	providerResp := &types.ProviderResponse{
		StatusCode: resp.StatusCode,
		Headers:    resp.Header,
		Body:       bodyBytes,
		Stream:     false,
	}

	claudeResp, err := provider.ConvertToClaudeResponse(providerResp)
	if err != nil {
		c.JSON(500, gin.H{"error": "Failed to convert response"})
		return
	}

	// å¦‚æœä¸Šæ¸¸æ²¡æœ‰è¿”å› Usageï¼Œæœ¬åœ°ä¼°ç®—
	if claudeResp.Usage == nil {
		claudeResp.Usage = &types.Usage{
			InputTokens:  utils.EstimateRequestTokens(requestBody),
			OutputTokens: utils.EstimateResponseTokens(claudeResp.Content),
		}
	}

	// ç›‘å¬å“åº”å…³é—­äº‹ä»¶(å®¢æˆ·ç«¯æ–­å¼€è¿æ¥)
	closeNotify := c.Writer.CloseNotify()
	go func() {
		select {
		case <-closeNotify:
			// æ£€æŸ¥å“åº”æ˜¯å¦å·²å®Œæˆ
			if !c.Writer.Written() {
				if envCfg.EnableResponseLogs {
					responseTime := time.Since(startTime).Milliseconds()
					log.Printf("â±ï¸ å“åº”ä¸­æ–­: %dms, çŠ¶æ€: %d", responseTime, resp.StatusCode)
				}
			}
		case <-time.After(10 * time.Second):
			// è¶…æ—¶é€€å‡ºgoroutine,é¿å…æ³„æ¼
			return
		}
	}()

	// è½¬å‘ä¸Šæ¸¸å“åº”å¤´åˆ°å®¢æˆ·ç«¯ï¼ˆé€æ˜ä»£ç†ï¼‰
	utils.ForwardResponseHeaders(resp.Header, c.Writer)

	c.JSON(200, claudeResp)

	// å“åº”å®Œæˆåè®°å½•
	if envCfg.EnableResponseLogs {
		responseTime := time.Since(startTime).Milliseconds()
		log.Printf("â±ï¸ å“åº”å‘é€å®Œæˆ: %dms, çŠ¶æ€: %d", responseTime, resp.StatusCode)
	}
}

// handleStreamResponse å¤„ç†æµå¼å“åº”
func handleStreamResponse(c *gin.Context, resp *http.Response, provider providers.Provider, envCfg *config.EnvConfig, startTime time.Time, upstream *config.UpstreamConfig, requestBody []byte) {
	defer resp.Body.Close()

	eventChan, errChan, err := provider.HandleStreamResponse(resp.Body)
	if err != nil {
		c.JSON(500, gin.H{"error": "Failed to handle stream response"})
		return
	}

	// å…ˆè½¬å‘ä¸Šæ¸¸å“åº”å¤´ï¼ˆé€æ˜ä»£ç†ï¼‰
	utils.ForwardResponseHeaders(resp.Header, c.Writer)

	// è®¾ç½® SSE å“åº”å¤´ï¼ˆå¯èƒ½è¦†ç›–ä¸Šæ¸¸çš„ Content-Typeï¼‰
	c.Header("Content-Type", "text/event-stream")
	c.Header("Cache-Control", "no-cache")
	c.Header("Connection", "keep-alive")
	c.Header("X-Accel-Buffering", "no")

	c.Status(200)

	var logBuffer bytes.Buffer
	var synthesizer *utils.StreamSynthesizer
	streamLoggingEnabled := envCfg.IsDevelopment() && envCfg.EnableResponseLogs
	if streamLoggingEnabled {
		synthesizer = utils.NewStreamSynthesizer(upstream.ServiceType)
	}

	w := c.Writer
	flusher, ok := w.(http.Flusher)
	if !ok {
		log.Printf("âš ï¸ ResponseWriterä¸æ”¯æŒFlushæ¥å£")
		return
	}
	flusher.Flush()

	clientGone := false
	hasUsage := false                 // è·Ÿè¸ªæ˜¯å¦å·²æ”¶åˆ° usage
	var outputTextBuffer bytes.Buffer // ç´¯ç§¯è¾“å‡ºæ–‡æœ¬ç”¨äºä¼°ç®— token
	for {
		select {
		case event, ok := <-eventChan:
			if !ok {
				// é€šé“å…³é—­ï¼Œæµå¼ä¼ è¾“ç»“æŸ
				if envCfg.EnableResponseLogs {
					responseTime := time.Since(startTime).Milliseconds()
					log.Printf("â±ï¸ æµå¼å“åº”å®Œæˆ: %dms", responseTime)

					// æ‰“å°å®Œæ•´çš„å“åº”å†…å®¹
					if envCfg.IsDevelopment() {
						if synthesizer != nil {
							synthesizedContent := synthesizer.GetSynthesizedContent()
							parseFailed := synthesizer.IsParseFailed()
							if synthesizedContent != "" && !parseFailed {
								log.Printf("ğŸ›°ï¸  ä¸Šæ¸¸æµå¼å“åº”åˆæˆå†…å®¹:\n%s", strings.TrimSpace(synthesizedContent))
							} else if logBuffer.Len() > 0 {
								log.Printf("ğŸ›°ï¸  ä¸Šæ¸¸æµå¼å“åº”åŸå§‹å†…å®¹:\n%s", logBuffer.String())
							}
						} else if logBuffer.Len() > 0 {
							// synthesizerä¸ºnilæ—¶ï¼Œç›´æ¥æ‰“å°åŸå§‹å†…å®¹
							log.Printf("ğŸ›°ï¸  ä¸Šæ¸¸æµå¼å“åº”åŸå§‹å†…å®¹:\n%s", logBuffer.String())
						}
					}
				}
				return
			}

			// ä½¿ç”¨ JSON è§£æç²¾ç¡®æ£€æµ‹ usage å­—æ®µ
			if !hasUsage {
				hasUsage = checkEventHasUsage(event)
			}

			// æå–æ–‡æœ¬å†…å®¹ç”¨äºä¼°ç®—è¾“å‡º token
			extractTextFromEvent(event, &outputTextBuffer)

			// ç¼“å­˜äº‹ä»¶ç”¨äºæœ€åçš„æ—¥å¿—è¾“å‡º
			if streamLoggingEnabled {
				logBuffer.WriteString(event)
				if synthesizer != nil {
					lines := strings.Split(event, "\n")
					for _, line := range lines {
						synthesizer.ProcessLine(line)
					}
				}
			}

			// æ£€æµ‹ message_stop äº‹ä»¶ï¼Œåœ¨å…¶ä¹‹å‰æ³¨å…¥ usageï¼ˆå¦‚æœéœ€è¦ï¼‰
			if !hasUsage && !clientGone && isMessageStopEvent(event) {
				usageEvent := buildUsageEvent(requestBody, outputTextBuffer.String())
				w.Write([]byte(usageEvent))
				flusher.Flush()
				hasUsage = true // é˜²æ­¢é‡å¤æ³¨å…¥
			}

			// å®æ—¶è½¬å‘ç»™å®¢æˆ·ç«¯ï¼ˆæµå¼ä¼ è¾“ï¼‰
			if !clientGone {
				_, err := w.Write([]byte(event))
				if err != nil {
					clientGone = true // æ ‡è®°å®¢æˆ·ç«¯å·²æ–­å¼€ï¼Œåœæ­¢åç»­å†™å…¥
					errMsg := err.Error()
					if strings.Contains(errMsg, "broken pipe") || strings.Contains(errMsg, "connection reset") {
						if envCfg.ShouldLog("info") {
							log.Printf("â„¹ï¸ å®¢æˆ·ç«¯ä¸­æ–­è¿æ¥ (æ­£å¸¸è¡Œä¸º)ï¼Œç»§ç»­æ¥æ”¶ä¸Šæ¸¸æ•°æ®...")
						}
					} else {
						log.Printf("âš ï¸ æµå¼ä¼ è¾“å†™å…¥é”™è¯¯: %v", err)
					}
					// æ³¨æ„ï¼šè¿™é‡Œä¸å†returnï¼Œè€Œæ˜¯ç»§ç»­å¾ªç¯ä»¥è€—å°½eventChan
				} else {
					flusher.Flush()
				}
			}

		case err, ok := <-errChan:
			if !ok {
				// errChanå…³é—­ï¼Œä½†è¿™ä¸ä¸€å®šæ„å‘³ç€æµç»“æŸï¼Œç»§ç»­ç­‰å¾…eventChan
				continue
			}
			if err != nil {
				// çœŸçš„æœ‰é”™è¯¯å‘ç”Ÿ
				log.Printf("ğŸ’¥ æµå¼ä¼ è¾“é”™è¯¯: %v", err)

				// æ‰“å°å·²æ¥æ”¶åˆ°çš„éƒ¨åˆ†å“åº”
				if envCfg.EnableResponseLogs && envCfg.IsDevelopment() {
					if synthesizer != nil {
						synthesizedContent := synthesizer.GetSynthesizedContent()
						if synthesizedContent != "" && !synthesizer.IsParseFailed() {
							log.Printf("ğŸ›°ï¸  ä¸Šæ¸¸æµå¼å“åº”åˆæˆå†…å®¹ (éƒ¨åˆ†):\n%s", strings.TrimSpace(synthesizedContent))
						} else if logBuffer.Len() > 0 {
							log.Printf("ğŸ›°ï¸  ä¸Šæ¸¸æµå¼å“åº”åŸå§‹å†…å®¹ (éƒ¨åˆ†):\n%s", logBuffer.String())
						}
					}
				}
				return
			}
		}
	}
}

// shouldRetryWithNextKey åˆ¤æ–­æ˜¯å¦åº”è¯¥ä½¿ç”¨ä¸‹ä¸€ä¸ªå¯†é’¥é‡è¯•
// è¿”å›: (shouldFailover bool, isQuotaRelated bool)
func shouldRetryWithNextKey(statusCode int, bodyBytes []byte) (bool, bool) {
	// 401/403 é€šå¸¸æ˜¯è®¤è¯é—®é¢˜
	if statusCode == 401 || statusCode == 403 {
		return true, false
	}

	// 429 é€Ÿç‡é™åˆ¶ï¼Œåˆ‡æ¢ä¸‹ä¸€ä¸ªå¯†é’¥
	if statusCode == 429 {
		return true, true
	}

	isQuotaRelated := false

	// æ£€æŸ¥é”™è¯¯æ¶ˆæ¯
	var errResp map[string]interface{}
	if err := json.Unmarshal(bodyBytes, &errResp); err == nil {
		if errObj, ok := errResp["error"].(map[string]interface{}); ok {
			if msg, ok := errObj["message"].(string); ok {
				msgLower := strings.ToLower(msg)
				if strings.Contains(msgLower, "insufficient") ||
					strings.Contains(msgLower, "invalid") ||
					strings.Contains(msgLower, "unauthorized") ||
					strings.Contains(msgLower, "quota") ||
					strings.Contains(msgLower, "rate limit") ||
					strings.Contains(msg, "è¯·æ±‚æ•°é™åˆ¶") ||
					strings.Contains(msgLower, "credit") ||
					strings.Contains(msgLower, "balance") {

					// åˆ¤æ–­æ˜¯å¦ä¸ºé¢åº¦/ä½™é¢ç›¸å…³
					if strings.Contains(msgLower, "ç§¯åˆ†ä¸è¶³") ||
						strings.Contains(msgLower, "insufficient") ||
						strings.Contains(msgLower, "credit") ||
						strings.Contains(msgLower, "balance") ||
						strings.Contains(msgLower, "quota") ||
						strings.Contains(msg, "è¯·æ±‚æ•°é™åˆ¶") {
						isQuotaRelated = true
					}
					return true, isQuotaRelated
				}
			}

			if errType, ok := errObj["type"].(string); ok {
				errTypeLower := strings.ToLower(errType)
				if strings.Contains(errTypeLower, "permission") ||
					strings.Contains(errTypeLower, "insufficient") ||
					strings.Contains(errTypeLower, "over_quota") ||
					strings.Contains(errTypeLower, "billing") {

					// åˆ¤æ–­æ˜¯å¦ä¸ºé¢åº¦/ä½™é¢ç›¸å…³
					if strings.Contains(errTypeLower, "over_quota") ||
						strings.Contains(errTypeLower, "billing") ||
						strings.Contains(errTypeLower, "insufficient") {
						isQuotaRelated = true
					}
					return true, isQuotaRelated
				}
			}
		}
	}

	// 500+ é”™è¯¯ä¹Ÿå¯ä»¥å°è¯• failover
	if statusCode >= 500 {
		return true, false
	}

	return false, false
}

// maskAPIKey æ©ç APIå¯†é’¥ï¼ˆä¸ TS ç‰ˆæœ¬ä¿æŒä¸€è‡´ï¼‰
func maskAPIKey(key string) string {
	if key == "" {
		return ""
	}

	length := len(key)
	if length <= 10 {
		// çŸ­å¯†é’¥ï¼šä¿ç•™å‰3ä½å’Œå2ä½
		if length <= 5 {
			return "***"
		}
		return key[:3] + "***" + key[length-2:]
	}

	// é•¿å¯†é’¥ï¼šä¿ç•™å‰8ä½å’Œå5ä½
	return key[:8] + "***" + key[length-5:]
}

// buildUsageEvent æ„å»ºå¸¦ usage çš„ message_delta SSE äº‹ä»¶
func buildUsageEvent(requestBody []byte, outputText string) string {
	inputTokens := utils.EstimateRequestTokens(requestBody)
	outputTokens := utils.EstimateTokens(outputText)

	event := map[string]interface{}{
		"type": "message_delta",
		"usage": map[string]int{
			"input_tokens":  inputTokens,
			"output_tokens": outputTokens,
		},
	}
	eventJSON, _ := json.Marshal(event)
	return fmt.Sprintf("event: message_delta\ndata: %s\n\n", eventJSON)
}

// checkEventHasUsage ä½¿ç”¨ JSON è§£æç²¾ç¡®æ£€æµ‹äº‹ä»¶æ˜¯å¦åŒ…å« usage å­—æ®µ
func checkEventHasUsage(event string) bool {
	for _, line := range strings.Split(event, "\n") {
		if !strings.HasPrefix(line, "data: ") {
			continue
		}
		jsonStr := strings.TrimPrefix(line, "data: ")

		var data map[string]interface{}
		if err := json.Unmarshal([]byte(jsonStr), &data); err != nil {
			continue
		}

		// æ£€æŸ¥é¡¶å±‚ usage å­—æ®µ
		if hasUsageFields(data["usage"]) {
			return true
		}

		// æ£€æŸ¥ message.usageï¼ˆClaude æµå¼å“åº”æ ¼å¼ï¼‰
		if msg, ok := data["message"].(map[string]interface{}); ok {
			if hasUsageFields(msg["usage"]) {
				return true
			}
		}
	}
	return false
}

// hasUsageFields æ£€æŸ¥ usage å¯¹è±¡æ˜¯å¦åŒ…å« token å­—æ®µ
func hasUsageFields(usage interface{}) bool {
	if u, ok := usage.(map[string]interface{}); ok {
		_, hasInput := u["input_tokens"]
		_, hasOutput := u["output_tokens"]
		return hasInput || hasOutput
	}
	return false
}

// isMessageStopEvent ä½¿ç”¨ JSON è§£ææ£€æµ‹æ˜¯å¦ä¸º message_stop äº‹ä»¶
func isMessageStopEvent(event string) bool {
	// å…ˆæ£€æŸ¥ event: è¡Œ
	if strings.Contains(event, "event: message_stop") {
		return true
	}

	// å†æ£€æŸ¥ data ä¸­çš„ type å­—æ®µ
	for _, line := range strings.Split(event, "\n") {
		if !strings.HasPrefix(line, "data: ") {
			continue
		}
		jsonStr := strings.TrimPrefix(line, "data: ")

		var data map[string]interface{}
		if err := json.Unmarshal([]byte(jsonStr), &data); err != nil {
			continue
		}

		if data["type"] == "message_stop" {
			return true
		}
	}
	return false
}

// extractTextFromEvent ä» SSE äº‹ä»¶ä¸­æå–æ–‡æœ¬å†…å®¹
func extractTextFromEvent(event string, buf *bytes.Buffer) {
	for _, line := range strings.Split(event, "\n") {
		if !strings.HasPrefix(line, "data: ") {
			continue
		}
		jsonStr := strings.TrimPrefix(line, "data: ")

		var data map[string]interface{}
		if err := json.Unmarshal([]byte(jsonStr), &data); err != nil {
			continue
		}

		// Claude SSE: delta.text (text_delta ç±»å‹)
		if delta, ok := data["delta"].(map[string]interface{}); ok {
			if text, ok := delta["text"].(string); ok {
				buf.WriteString(text)
			}
			// tool_use: delta.partial_json
			if partialJSON, ok := delta["partial_json"].(string); ok {
				buf.WriteString(partialJSON)
			}
		}

		// content_block_start ä¸­çš„åˆå§‹æ–‡æœ¬
		if cb, ok := data["content_block"].(map[string]interface{}); ok {
			if text, ok := cb["text"].(string); ok {
				buf.WriteString(text)
			}
		}
	}
}
