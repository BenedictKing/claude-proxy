// Package common æä¾› handlers æ¨¡å—çš„å…¬å…±åŠŸèƒ½
package common

import (
	"bytes"
	"encoding/json"
	"fmt"
	"io"
	"log"
	"net/http"
	"time"

	"github.com/BenedictKing/claude-proxy/internal/config"
	"github.com/BenedictKing/claude-proxy/internal/httpclient"
	"github.com/BenedictKing/claude-proxy/internal/metrics"
	"github.com/BenedictKing/claude-proxy/internal/utils"
	"github.com/gin-gonic/gin"
)

// ReadRequestBody è¯»å–å¹¶éªŒè¯è¯·æ±‚ä½“å¤§å°
// è¿”å›ž: (bodyBytes, error)
// å¦‚æžœè¯·æ±‚ä½“è¿‡å¤§ï¼Œä¼šè‡ªåŠ¨è¿”å›ž 413 é”™è¯¯å¹¶æŽ’ç©ºå‰©ä½™æ•°æ®
func ReadRequestBody(c *gin.Context, maxBodySize int64) ([]byte, error) {
	limitedReader := io.LimitReader(c.Request.Body, maxBodySize+1)
	bodyBytes, err := io.ReadAll(limitedReader)
	if err != nil {
		c.JSON(400, gin.H{"error": "Failed to read request body"})
		return nil, err
	}

	if int64(len(bodyBytes)) > maxBodySize {
		// æŽ’ç©ºå‰©ä½™è¯·æ±‚ä½“ï¼Œé¿å… keep-alive è¿žæŽ¥æ±¡æŸ“
		io.Copy(io.Discard, c.Request.Body)
		c.JSON(413, gin.H{"error": fmt.Sprintf("Request body too large, maximum size is %d MB", maxBodySize/1024/1024)})
		return nil, fmt.Errorf("request body too large")
	}

	// æ¢å¤è¯·æ±‚ä½“ä¾›åŽç»­ä½¿ç”¨
	c.Request.Body = io.NopCloser(bytes.NewReader(bodyBytes))
	return bodyBytes, nil
}

// RestoreRequestBody æ¢å¤è¯·æ±‚ä½“ä¾›åŽç»­ä½¿ç”¨
func RestoreRequestBody(c *gin.Context, bodyBytes []byte) {
	c.Request.Body = io.NopCloser(bytes.NewReader(bodyBytes))
}

// SendRequest å‘é€ HTTP è¯·æ±‚åˆ°ä¸Šæ¸¸
// isStream: æ˜¯å¦ä¸ºæµå¼è¯·æ±‚ï¼ˆæµå¼è¯·æ±‚ä½¿ç”¨æ— è¶…æ—¶å®¢æˆ·ç«¯ï¼‰
func SendRequest(req *http.Request, upstream *config.UpstreamConfig, envCfg *config.EnvConfig, isStream bool) (*http.Response, error) {
	clientManager := httpclient.GetManager()

	var client *http.Client
	if isStream {
		client = clientManager.GetStreamClient(upstream.InsecureSkipVerify)
	} else {
		timeout := time.Duration(envCfg.RequestTimeout) * time.Millisecond
		client = clientManager.GetStandardClient(timeout, upstream.InsecureSkipVerify)
	}

	if upstream.InsecureSkipVerify && envCfg.EnableRequestLogs {
		log.Printf("âš ï¸ æ­£åœ¨è·³è¿‡å¯¹ %s çš„TLSè¯ä¹¦éªŒè¯", req.URL.String())
	}

	if envCfg.EnableRequestLogs {
		log.Printf("ðŸŒ å®žé™…è¯·æ±‚URL: %s", req.URL.String())
		log.Printf("ðŸ“¤ è¯·æ±‚æ–¹æ³•: %s", req.Method)
		if envCfg.IsDevelopment() {
			logRequestDetails(req, envCfg)
		}
	}

	return client.Do(req)
}

// logRequestDetails è®°å½•è¯·æ±‚è¯¦æƒ…ï¼ˆä»…å¼€å‘æ¨¡å¼ï¼‰
func logRequestDetails(req *http.Request, envCfg *config.EnvConfig) {
	// å¯¹è¯·æ±‚å¤´åšæ•æ„Ÿä¿¡æ¯è„±æ•
	reqHeaders := make(map[string]string)
	for key, values := range req.Header {
		if len(values) > 0 {
			reqHeaders[key] = values[0]
		}
	}
	maskedReqHeaders := utils.MaskSensitiveHeaders(reqHeaders)
	var reqHeadersJSON []byte
	if envCfg.RawLogOutput {
		reqHeadersJSON, _ = json.Marshal(maskedReqHeaders)
	} else {
		reqHeadersJSON, _ = json.MarshalIndent(maskedReqHeaders, "", "  ")
	}
	log.Printf("ðŸ“‹ å®žé™…è¯·æ±‚å¤´:\n%s", string(reqHeadersJSON))

	if req.Body != nil {
		bodyBytes, err := io.ReadAll(req.Body)
		if err == nil {
			req.Body = io.NopCloser(bytes.NewReader(bodyBytes))
			var formattedBody string
			if envCfg.RawLogOutput {
				formattedBody = utils.FormatJSONBytesRaw(bodyBytes)
			} else {
				formattedBody = utils.FormatJSONBytesForLog(bodyBytes, 500)
			}
			log.Printf("ðŸ“¦ å®žé™…è¯·æ±‚ä½“:\n%s", formattedBody)
		}
	}
}

// LogOriginalRequest è®°å½•åŽŸå§‹è¯·æ±‚ä¿¡æ¯
func LogOriginalRequest(c *gin.Context, bodyBytes []byte, envCfg *config.EnvConfig, apiType string) {
	if !envCfg.EnableRequestLogs {
		return
	}

	log.Printf("ðŸ“¥ æ”¶åˆ°%sè¯·æ±‚: %s %s", apiType, c.Request.Method, c.Request.URL.Path)

	if envCfg.IsDevelopment() {
		var formattedBody string
		if envCfg.RawLogOutput {
			formattedBody = utils.FormatJSONBytesRaw(bodyBytes)
		} else {
			formattedBody = utils.FormatJSONBytesForLog(bodyBytes, 500)
		}
		log.Printf("ðŸ“„ åŽŸå§‹è¯·æ±‚ä½“:\n%s", formattedBody)

		sanitizedHeaders := make(map[string]string)
		for key, values := range c.Request.Header {
			if len(values) > 0 {
				sanitizedHeaders[key] = values[0]
			}
		}
		maskedHeaders := utils.MaskSensitiveHeaders(sanitizedHeaders)
		var headersJSON []byte
		if envCfg.RawLogOutput {
			headersJSON, _ = json.Marshal(maskedHeaders)
		} else {
			headersJSON, _ = json.MarshalIndent(maskedHeaders, "", "  ")
		}
		log.Printf("ðŸ“¥ åŽŸå§‹è¯·æ±‚å¤´:\n%s", string(headersJSON))
	}
}

// AreAllKeysSuspended æ£€æŸ¥æ¸ é“çš„æ‰€æœ‰ Key æ˜¯å¦éƒ½å¤„äºŽç†”æ–­çŠ¶æ€
// ç”¨äºŽåˆ¤æ–­æ˜¯å¦éœ€è¦å¯ç”¨å¼ºåˆ¶æŽ¢æµ‹æ¨¡å¼
func AreAllKeysSuspended(metricsManager *metrics.MetricsManager, baseURL string, apiKeys []string) bool {
	if len(apiKeys) == 0 {
		return false
	}

	for _, apiKey := range apiKeys {
		if !metricsManager.ShouldSuspendKey(baseURL, apiKey) {
			return false
		}
	}
	return true
}

// ExtractUserID ä»Žè¯·æ±‚ä½“ä¸­æå– user_idï¼ˆç”¨äºŽ Messages APIï¼‰
func ExtractUserID(bodyBytes []byte) string {
	var req struct {
		Metadata struct {
			UserID string `json:"user_id"`
		} `json:"metadata"`
	}
	if err := json.Unmarshal(bodyBytes, &req); err == nil {
		return req.Metadata.UserID
	}
	return ""
}

// ExtractConversationID ä»Žè¯·æ±‚ä¸­æå–å¯¹è¯æ ‡è¯†ï¼ˆç”¨äºŽ Responses APIï¼‰
// ä¼˜å…ˆçº§: Conversation_id Header > Session_id Header > prompt_cache_key > metadata.user_id
func ExtractConversationID(c *gin.Context, bodyBytes []byte) string {
	// 1. HTTP Header: Conversation_id
	if convID := c.GetHeader("Conversation_id"); convID != "" {
		return convID
	}

	// 2. HTTP Header: Session_id
	if sessID := c.GetHeader("Session_id"); sessID != "" {
		return sessID
	}

	// 3. Request Body: prompt_cache_key æˆ– metadata.user_id
	var req struct {
		PromptCacheKey string `json:"prompt_cache_key"`
		Metadata       struct {
			UserID string `json:"user_id"`
		} `json:"metadata"`
	}
	if err := json.Unmarshal(bodyBytes, &req); err == nil {
		if req.PromptCacheKey != "" {
			return req.PromptCacheKey
		}
		if req.Metadata.UserID != "" {
			return req.Metadata.UserID
		}
	}

	return ""
}
